{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: model_dataset\n",
    "\n",
    "<img src=\"./images/model_dataset.png\"/>\n",
    "\n",
    "Part explanation for the columns:  \n",
    "1. label_group (obeject): 4 groups of resonse to offers\n",
    "    - 'none_offer'\n",
    "    - 'no_care'\n",
    "    - 'tried'\n",
    "    - 'effective_offer'\n",
    "2. label_seg (int): 12 segments based on age and income\n",
    "    - values: 1 ... 12  <br>  \n",
    "  \n",
    "(More details in <u>2_heuristic_exploration.ipynb</u>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <u>10 Kinds</u> of offer_id\n",
    "| offer_id #| type | duration | requirement | reward |\n",
    "|:-| :-| :-:|:-:|:-:|\n",
    "| 0 | bogo | 7 | 10 | 10 |\n",
    "| 1 | bogo | 5 | 10 | 10 |\n",
    "| 2 | infomational | 4 | - | - |\n",
    "| 3 | bogo | 7 | 5 | 5 |\n",
    "| 4 | discount | 10 | 20 | 5 |\n",
    "| 5 | discount | 7 | 7 | 3 |\n",
    "| 6 | discount | 10 | 10 | 2 |\n",
    "| 7 | informational | 3 | - | - |\n",
    "| 8 | bogo | 5 | 5 | 5 |\n",
    "| 9 | discount | 7 | 10 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>12 Segements</u> based on 'age' and 'gender'\n",
    "<br>\n",
    "    \n",
    "|Segment #| Age Group (edge included)<br> (Experiment in 2018) | Income | \n",
    "|---| --- | --- | \n",
    "|1| Millenials(-21 & 22-37) | low  | \n",
    "|2| Millenials(-21 & 22-37) | medium  | \n",
    "|3| Millenials(-21 & 22-37) | high  | \n",
    "|4| Gen X(38-53) | low  |\n",
    "|5| Gen X(38-53) | medium |\n",
    "|6| Gen X(38-53) | high |\n",
    "|7| Baby Boomer(54-72) | low  |\n",
    "|8| Baby Boomer(54-72) | medium |\n",
    "|9| Baby Boomer(54-72) | high |\n",
    "|10| Silent(73-90 & 91+) |low |\n",
    "|11| Silent(73-90 & 91+) | medium |\n",
    "|12| Silent(73-90 & 91+) | high |\n",
    "\n",
    "**Notice:**  \n",
    "- low: 30,000-50,000\n",
    "- medium: 50,001-82,500\n",
    "- high: 82,501-120,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>4 Groups</u> of possible responsiveness to offer\n",
    "<br>\n",
    "\n",
    "|Group| received | viewed |valid completed | transaction amount |Scenario |\n",
    "| :-| :-: | :-:| :-: | :-: | :- |\n",
    "|1.none_offer| 0 | 0 | 0 | |haven't received the offer |\n",
    "|2.no_care | 1 | 0 | - | |received but not viewed.<br> regarded as no_care|\n",
    "|| 1 | 1 | 0 | =0.0 | received, viewed but no transaction |\n",
    "|| 1 | 1 | 1<br>viewed after completed |  | received, but completed unintentionally |\n",
    "|3.tried| 1 | 1 | 0 | >0.0|received, viewed, have transaction |\n",
    "|4.effctive_offer | 1 | 1 | 1<br>viewed before completed | | viewed before completed,  effctive offer|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a class=\"anchor\" id=\"Start\">Table of Contents</a>\n",
    "\n",
    "I. [Feature Engineer](#1)<br>\n",
    "II.[Build model Pipeline](#2)<br>\n",
    "III.[Explore intersting Questions](#3)\n",
    "\n",
    "    - Q3.1 Offer prepared to sent to a person, is this offer effective?\n",
    "    - Q3.2 Offer already sent to a person, is this offer effective?\n",
    "    - Q3.3 Given a person, recommend an offer with the most effctivity?\n",
    "IV.[Build Neural Network for Regeression](#4)<br>\n",
    "[References](#References)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "from time import time\n",
    "from datetime import date\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model_dataset_raw = pd.read_csv('./data_generated/model_dataset_raw.csv', dtype={'offer_id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"1\">[I. Feature Engineer](#Start)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Add features\n",
    "- Total transactions amount of individuals `'amount_total'`\n",
    "- Count of offers received of individuals  `'offer_received_cnt'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in transactions dataset\n",
    "\n",
    "# wrangled transcript with updated information of offer\n",
    "transcript_offer = pd.read_csv('./data_generated/wrangled_transcript_offer.csv', dtype={'person': int})\n",
    "# recover to original dataset: index is the same\n",
    "transcript_offer.index = transcript_offer.iloc[:, 0].values\n",
    "del transcript_offer['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_amount = transcript_offer.groupby('person').sum()['amount']\n",
    "offer_received_cnt = model_dataset_raw.groupby(['person']).count()['offer_id']\n",
    "persons = transcript_amount.index.tolist()\n",
    "\n",
    "for person in persons:\n",
    "    is_person = (model_dataset_raw.person == person)\n",
    "    model_dataset_raw.loc[is_person,'amount_total'] = transcript_amount.loc[person]\n",
    "    model_dataset_raw.loc[is_person,'offer_received_cnt'] = offer_received_cnt.loc[person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = model_dataset_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.groupby('label_group').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOUND:**\n",
    "1. The 5 person in group `none_offer` will be droped, so that there is no more NaNs in the target columns in `model_dataset` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_dataset_kepp = (model_dataset.label_group != 'none_offer')\n",
    "model_dataset = model_dataset[is_dataset_kepp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. One-hot code for target obejects\n",
    "- gender\n",
    "- label_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_onehot = pd.get_dummies(model_dataset['gender'], prefix='gender')\n",
    "label_group_onehot = pd.get_dummies(model_dataset['label_group'], prefix='group')\n",
    "offer_id_onehot =  pd.get_dummies(model_dataset['offer_id'], prefix='offer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = pd.concat([model_dataset, gender_onehot, label_group_onehot, offer_id_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Features of time\n",
    "1. Time features\n",
    "    - 'time_received'\n",
    "    - 'time_viewed'\n",
    "    - 'time_transaction'\n",
    "    - 'time_completed'\n",
    "2. Transform the time_transaction to transaction_cnt\n",
    "3. Fill the NaNs with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset[(model_dataset.time_transaction.isin(['-1']))].offer_id.unique()  #-1标签 只对应offer_id.isin(['2','7']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_transaction_cnt(dataset):\n",
    "    # group of offer_id=='2' '7'\n",
    "    # group of transaction = -1\n",
    "    # group of transaction with ','\n",
    "    \n",
    "    dataset['time_transaction'] = dataset['time_transaction'].apply(lambda x: len(str(x).split(','))-1)\n",
    "    \n",
    "    is_group_info = (dataset.offer_id.isin(['2', '7']) & (dataset.label_effective_offer==1))\n",
    "    dataset.loc[is_group_info, 'time_transaction'] = 1\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "model_dataset = transform_transaction_cnt(model_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.rename(columns={'time_transaction': 'transaction_cnt'}, inplace=True)\n",
    "\n",
    "# drop the useless columns for modeling\n",
    "model_dataset.drop(['label_effective_offer'], axis=1, inplace=True)\n",
    "\n",
    "values = {'time_viewed': 0.0, 'time_completed': 0.0} #time_viewed: 49860 non-null, time_completed: 40407 non-null\n",
    "model_dataset.fillna(value=values, inplace=True)\n",
    "\n",
    "model_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"2\">[II. Build model Pipeline](#Start)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方便重启\n",
    "model_dataset_test = model_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = model_dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select features and target \n",
    "[References[1]](https://github.com/syuenloh/UdacityDataScientistCapstone/blob/master/Starbucks%20Capstone%20Challenge%20-%20Using%20Starbucks%20app%20user%20data%20to%20predict%20effective%20offers.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target: label_group\n",
    "model_dataset['label_group'] = model_dataset['label_group'].replace(['no_care','tried', 'effctive_offer'],['0','1','1'])\n",
    "model_dataset = model_dataset.astype({'label_group': int})\n",
    "\n",
    "model_dataset.groupby('label_group').count()  \n",
    "# 31613\t VS 34888: The distribution of the targets seems balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_target(df, target_cols, keep_cols):\n",
    "    '''\n",
    "    INPUT:\n",
    "    - df(DataFrame): dataset include all possible features and target\n",
    "    - target_cols: \n",
    "        a column name(str) or more columns names(list of str)\n",
    "    - keep_cols(list): list of columns names as features\n",
    "    \n",
    "    OUTPUT:\n",
    "    - \n",
    "    '''\n",
    "    # df[[]] is DataFrame\n",
    "    target = df[target_cols] #np.array()\n",
    "    \n",
    "    drop_cols = np.setdiff1d(df.columns, keep_cols)\n",
    "    features = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. prepare model pipeline\n",
    "[References[1]](https://github.com/syuenloh/UdacityDataScientistCapstone/blob/master/Starbucks%20Capstone%20Challenge%20-%20Using%20Starbucks%20app%20user%20data%20to%20predict%20effective%20offers.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_clf(pickle_path, clf_ls, features, target, test_size=0.20, random_state=9):\n",
    "    '''\n",
    "    OUTPUT:\n",
    "    - results(dict): 'model', 'train_time', 'pred_time', 'train_score', 'test_score'\n",
    "    '''\n",
    "    # split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=random_state)\n",
    "    \n",
    "    results = defaultdict()\n",
    "    visual_results = pd.DataFrame(columns=['model', 'train_time', 'test_time',\n",
    "                                         'train_score', 'test_score'])\n",
    "    #models = defaultdict()\n",
    "    #report_ls = []\n",
    "    \n",
    "    \n",
    "    for classifier in clf_ls:\n",
    "        pipe = Pipeline(steps=[('preprocessor', StandardScaler()),\n",
    "                               ('clf', classifier)])\n",
    "                           \n",
    "        start_train = time()\n",
    "        model = pipe.fit(X_train, y_train)\n",
    "        end_train = time()\n",
    "        results['train_time'] = end_train-start_train\n",
    "        \n",
    "        # predict in train set\n",
    "        pred_train = model.predict(X_train)\n",
    "        \n",
    "        # predict in test set and Calculate the time\n",
    "        start_test = time()\n",
    "        pred_test = model.predict(X_test)\n",
    "        end_test = time()\n",
    "        results['test_time'] = end_test-start_test\n",
    "    \n",
    "        # add training accuracy to results\n",
    "        # what is the score？\n",
    "        results['train_score']=model.score(X_train,y_train)\n",
    "    \n",
    "        #add testing accuracy to results\n",
    "        results['test_score']=model.score(X_test,y_test)\n",
    "        \n",
    "        \n",
    "        print(\"{} trained on {} samples.\".format(classifier.__class__.__name__, len(y_train)))\n",
    "        print(\"Train time: {}s\".format(results['train_time']))\n",
    "        print(\"Test time: {}s\".format(results['test_time']))\n",
    "        print(\"MSE_train: %.4f\" % mean_squared_error(y_train,pred_train))\n",
    "        print(\"MSE_test: %.4f\" % mean_squared_error(y_test,pred_test))\n",
    "        print(\"Training accuracy: %.4f\" % results['train_score'])\n",
    "        print(\"Test accuracy: %.4f\" % results['test_score'])\n",
    "        \n",
    "        # output the report\n",
    "        report = classification_report(y_test, pred_test,digits=4) #output_dict=True\n",
    "        print(report)\n",
    "                # df_report = pd.DataFrame(report).transpose()\n",
    "                # report_ls.append(df_report)\n",
    "        \n",
    "        # for scaler value need an index\n",
    "        new_model = pd.Series([classifier.__class__.__name__, results['train_time'],\n",
    "                            results['test_time'], results['train_score'], results['test_score']],\n",
    "                           index=visual_results.columns)\n",
    "        visual_results = visual_results.append(new_model, ignore_index=True)\n",
    "        \n",
    "        #models[classifier.__class__.__name__] = model\n",
    "        #覆盖之后只写入了最后一个模型\n",
    "        with open(pickle_path, \"wb\") as f:  \n",
    "                pickle.dump(model, f)\n",
    "        \n",
    "    return visual_results #,report_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_select_param(classifier, param_grid, features, target, test_size=0.20, random_state=9):\n",
    "    # split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=random_state)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('preprocessor', StandardScaler()),\n",
    "                        ('clf', classifier)])\n",
    "    CV = GridSearchCV(pipe, param_grid, n_jobs= 1)\n",
    "    \n",
    "    results = defaultdict()\n",
    "    \n",
    "    start = time()\n",
    "    CV.fit(X_train, y_train) \n",
    "    end = time()\n",
    "    \n",
    "    # Attribute: best_estimator_  best_params_  best_score_\n",
    "    results['model'] = CV\n",
    "    results['train_time'] = end - start\n",
    "    \n",
    "    # predict in train set\n",
    "    pred_train = CV.predict(X_train)\n",
    "\n",
    "    # predict in test set and Calculate the time\n",
    "    start_test = time()\n",
    "    pred_test = CV.predict(X_test)\n",
    "    end_test = time()\n",
    "    results['test_time'] = end_test-start_test\n",
    "\n",
    "    # add training accuracy to results\n",
    "    # what is the score？\n",
    "    results['train_score']=CV.score(X_train,y_train)\n",
    "\n",
    "    #add testing accuracy to results\n",
    "    results['test_score']=CV.score(X_test,y_test)\n",
    "\n",
    "    print(\"{} trained on {} samples.\".format(CV.best_estimator_, len(y_train)))\n",
    "    print(\"MSE_train: %.4f\" % mean_squared_error(y_train, pred_train))\n",
    "    print(\"MSE_test: %.4f\" % mean_squared_error(y_test, pred_test))\n",
    "    print(\"Training accuracy: %.4f\" % results['train_score'])\n",
    "    print(\"Test accuracy: %.4f\" % results['test_score'])\n",
    "    print(classification_report(y_test, pred_test,digits=4))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"3\">[III. Explore intersting Questions](#Start)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1 Offer prepared to sent to a person, is this offer effective?\n",
    "\n",
    "1. Dataset<br>\n",
    "Data in the group as follows in label_group:\n",
    "    - no_care\n",
    "    - tried\n",
    "    - effective_offer\n",
    "\n",
    "2. Target   \n",
    "\n",
    "| Target | Value | Meaning |\n",
    "| :- | :-: | :- |\n",
    "| label_group | 0 | person doesn't care the offer |\n",
    "|       | 1 | Within the duration of offer, tried or completed the transactions|\n",
    "\n",
    "3. Features\n",
    "\n",
    "| (Number: default 1)Features | Select reason |\n",
    "| :- | :- |\n",
    "| age | basic info about person |\n",
    "| income | basic info about person |\n",
    "| member_days | basic info about person |\n",
    "| (3)gender_ | basic info about person<br>(3 kinds of 0-1 variables) |\n",
    "| (10)offer_ | info about offer<br>(10 kinds of 0-1 variables) |\n",
    "| amount_total | amount paid of all transactions |\n",
    "| offer_received_cnt | number of all received offers |\n",
    "| time_received | receive time for this offer |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = 'label_group'\n",
    "\n",
    "keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "            'offer_0', 'offer_1', 'offer_2', 'offer_3', 'offer_4', 'offer_5',\n",
    "              'offer_6', 'offer_7', 'offer_8', 'offer_9',\n",
    "             'amount_total', 'offer_received_cnt','time_received']\n",
    "           \n",
    "features, target = select_features_target(model_dataset, target_cols, keep_cols)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    #SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    #NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "\n",
    "# test for ideal with group infos\n",
    "pickle_path = './models_effct_1.pckl'\n",
    "results_effct_1 = select_clf(pickle_path, classifiers, features, target, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_effct_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2 Offer already sent to a person, is this offer effective?\n",
    "\n",
    "1. Dataset<br>\n",
    "Data in the group as follows in label_group:\n",
    "    - no_care\n",
    "    - tried\n",
    "    - effective_offer\n",
    "\n",
    "\n",
    "2. Target   \n",
    "\n",
    "| Target | Value | Meaning |\n",
    "| :- | :-: | :- |\n",
    "| label_group | 0 | person doesn't care the offer |\n",
    "|       | 1 | Within the duration of offer, tried or completed the transactions|\n",
    "\n",
    "3. Features\n",
    "\n",
    "| (Number: default 1)Features | Select reason |\n",
    "| :- | :- |\n",
    "| age | basic info about person |\n",
    "| income | basic info about person |\n",
    "| member_days | basic info about person |\n",
    "| (3)gender_ | basic info about person<br>(3 kinds of 0-1 variables) |\n",
    "| (10)offer_ | info about offer<br>(10 kinds of 0-1 variables) |\n",
    "| amount_with_offer | amount paid of transactions for this offer |\n",
    "| amount_total | amount paid of all transactions |\n",
    "| offer_received_cnt | number of all received offers |\n",
    "| time_received | receive time for this offer |\n",
    "| time_viewed | view time for this offer. <br>If not, values 0.0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'group_effctive_offer', 'group_no_care', 'group_tried','transaction_cnt', 'time_completed' has direct information of target classes\n",
    "target_cols = 'label_group'\n",
    "\n",
    "keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "            'offer_0', 'offer_1', 'offer_2', 'offer_3', 'offer_4', 'offer_5',\n",
    "              'offer_6', 'offer_7', 'offer_8', 'offer_9',\n",
    "             'amount_with_offer', 'amount_total', 'offer_received_cnt',\n",
    "            'time_received', 'time_viewed']\n",
    "           \n",
    "features, target = select_features_target(model_dataset, target_cols, keep_cols)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    #SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    #NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "\n",
    "# test for ideal with group infos\n",
    "pickle_path = './models_rec_1.pckl'\n",
    "results_rec_1 = select_clf(pickle_path, classifiers, features, target, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rec_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model: feature_importances_\n",
    "with open(r\"./models_rec_1.pckl\", \"rb\") as f:\n",
    "    models = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "            'offer_0', 'offer_1', 'offer_2', 'offer_3', 'offer_4', 'offer_5',\n",
    "              'offer_6', 'offer_7', 'offer_8', 'offer_9',\n",
    "             'amount_with_offer', 'amount_total', 'offer_received_cnt',\n",
    "            'time_received', 'time_viewed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.DataFrame(models['clf'].feature_importances_, index=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(models['clf'].feature_importances_,\n",
    "                                   index = columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances.plot.bar()\n",
    "plt.xticks(rotation=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['clf'].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3 Given a person, recommend an offer with the most effctivity.\n",
    "\n",
    "定位：只有个人基本信息和汇总的情况，没有针对的offer\n",
    "\n",
    "1. Dataset<br>\n",
    "Data in the group as follows in label_group:\n",
    "    - tried——in this group exists transaction(s)\n",
    "    - effective_offer\n",
    "\n",
    "\n",
    "2. Target\n",
    "\n",
    "| Target | Value | Meaning |\n",
    "| :- | :-: | :- |\n",
    "| offer_(10 classes) | 0 | uneffective in this offer_id |\n",
    "|              | 1 | effective in this offer_id |\n",
    "\n",
    "3. Features\n",
    "\n",
    "| (Number: default 1)Features | Select reason |\n",
    "| :- | :- |\n",
    "| age | basic info about person |\n",
    "| income | basic info about person |\n",
    "| member_days | basic info about person |\n",
    "| (3)gender_ | basic info about person<br>(3 kinds of 0-1 variables) |\n",
    "| (10)offer_ | info about offer<br>(10 kinds of 0-1 variables) |\n",
    "| amount_with_offer | amount paid of transactions for this offer |\n",
    "| amount_total | amount paid of all transactions |\n",
    "| offer_received_cnt | number of all received offers |\n",
    "| time_received | receive time for this offer |\n",
    "| time_viewed | view time for this offer. <br>If not, values 0.0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_group_effective = (model_dataset.label_group==1)  #tried & effctive_offer\n",
    "model_dataset_input = model_dataset[is_group_effective]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset_input.groupby('offer_id').count()  #seems the samples is far from enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'group_effctive_offer', 'group_no_care', 'group_tried','transaction_cnt', 'time_completed' has direct information of target classes\n",
    "target_cols = ['offer_0', 'offer_1', 'offer_2', 'offer_3', 'offer_4', 'offer_5',\n",
    "              'offer_6', 'offer_7', 'offer_8', 'offer_9']\n",
    "\n",
    "#keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    " #            'amount_total', 'offer_received_cnt']\n",
    "\n",
    "keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "             'amount_with_offer', 'amount_total', 'offer_received_cnt',\n",
    "            'time_received', 'time_viewed']\n",
    "\n",
    "features, target = select_features_target(model_dataset_input,target_cols, keep_cols)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    #SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    #NuSVC(probability=True),\n",
    "    #DecisionTreeClassifier(),\n",
    "    #RandomForestClassifier(),\n",
    "    #AdaBoostClassifier(),  \n",
    "    MultiOutputClassifier(GradientBoostingClassifier())  #one-vs-the rest\n",
    "    ]\n",
    "\n",
    "# test for ideal with group infos\n",
    "pickle_path = './models_multiclass_test.pckl'\n",
    "results_multiclass_test = select_clf(pickle_path, classifiers, features, target, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./models_multiclass_test.pckl\", \"rb\") as f:\n",
    "    models_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_test.predict_proba(test) #概率：第一列为0， 第二列为1 10 lables * 3 recods * 2 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = features.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset_input[target_cols].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"4\">[IV. Build neural network for regeression](#Start)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputs=18, hidden=7, outputs=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(inputs, hidden)  # 18 features as input\n",
    "        self.fc2 = nn.Linear(hidden, outputs)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)  #单分类用sigmoid, 多分类soft_max...\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'group_effctive_offer', 'group_no_care', 'group_tried','transaction_cnt', 'time_completed' has direct information of target classes\n",
    "target_cols = 'amount_total'\n",
    "\n",
    "keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "             'reward', 'difficulty','duration', 'email', 'mobile', 'social', 'web',\n",
    "             'transaction_cnt', 'offer_received_cnt',\n",
    "             'group_effctive_offer', 'group_no_care', 'group_tried']\n",
    "            \n",
    "model_dataset_input = shuffle(model_dataset)\n",
    "features, target = select_features_target(model_dataset_input, target_cols, keep_cols)\n",
    "\n",
    "features_array, target_array = np.array(features), np.array(target)\n",
    "features_tensor, target_tensor = torch.from_numpy(features_array).float(), torch.from_numpy(target_array).float()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tensor, target_tensor, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model\n",
    "model = Classifier()  #default (29, 10, 4, 1)\n",
    "#criterion = nn.NLLLoss() #针对对分类变量\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# train the net\n",
    "epochs = 20\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    start = time()\n",
    "    running_loss = 0\n",
    "    for idx in range(train_size):\n",
    "        features, target = X_train[idx], y_train[idx]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): #测试阶段，不计算梯度\n",
    "        model.eval()  #测试阶段，附带取消dropout()\n",
    "        \n",
    "        for idx in range(test_size):\n",
    "            features, target = X_test[idx], y_test[idx]\n",
    "            \n",
    "            output = model(features)  #回归分析，没有标签accuracy的计算\n",
    "            test_loss += criterion(output, target)\n",
    "            \n",
    "    \n",
    "    train_losses.append(running_loss/train_size)\n",
    "    test_losses.append(test_loss/test_size)\n",
    "        \n",
    "    model.train()\n",
    "    end = time()\n",
    "    print(\"epoch:{}/{}..\" .format(e+1, epochs), \n",
    "        \"Training Loss: {:.3f}..\".format(running_loss/train_size),\n",
    "        \"Test Loss: {:.3f}..\".format(test_loss/test_size),\n",
    "        \"Time Cost: {:.3f}s..\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for ideal with group infos\n",
    "pickle_path = './models_rec_1.pckl'\n",
    "results_rec_1 = select_clf(pickle_path, classifiers, features, target, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(MyModule,\n",
    "                          max_epochs=10,\n",
    "                          lr=0.1,)\n",
    "\n",
    "                            \n",
    "                            \n",
    "\n",
    "# sklearn pipe & gridsearch\n",
    "pipe = Pipeline([('preprocessor', StandardScaler()),\n",
    "                 ('clf', net)\n",
    "                ])\n",
    "\n",
    "pipe.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"References\">[References](#Start)</a>\n",
    "[[1]Starbucks Capstone Challenge: Using Starbucks app user data to predict effective offers](https://github.com/syuenloh/UdacityDataScientistCapstone/blob/master/Starbucks%20Capstone%20Challenge%20-%20Using%20Starbucks%20app%20user%20data%20to%20predict%20effective%20offers.ipynb)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.offer_received_cnt.hist() #series 直接画图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.3 Conclusion](#Start)\n",
    "**Notice:**\n",
    "1. `offer_id == -1` means person haven't received any offer\n",
    "\n",
    "2. These 5 person(`offer_id=='-1'`) are the whole `label_effective_offer == -2` group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. In general\n",
    "1. There are just 5 person, who never received the offer  \n",
    "    - 2 in `segment \\#7`\n",
    "    - 1 in `segment \\#8 \\#9 \\#11`\n",
    "  \n",
    "2. The offer distributions under income: See `segment \\#3` VS. `segment \\#12`  \n",
    "    - Young people have not so much money. \n",
    "    - Elder people tend to have more savings.\n",
    "\n",
    "3. The offer distributions under age: See `segment \\#1` VS. `segment \\#10`\n",
    "    - In the low income group, compared with young person, the elder person seems to receive less offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. In subplots\n",
    "1. In each segment, person reveive almost the same quantity of offers \n",
    "2. In `Segment \\#3`\n",
    "    - Young person tends to lack of a big savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
