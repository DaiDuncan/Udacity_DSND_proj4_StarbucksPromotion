{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: model_dataset\n",
    "\n",
    "<img src=\"./images/model_dataset.png\"/>\n",
    "\n",
    "Explanation for part of columns:  \n",
    "1. label_group (obeject): 4 groups of resonse to offers\n",
    "    - 'none_offer'\n",
    "    - 'no_care'\n",
    "    - 'tried'\n",
    "    - 'effective_offer'\n",
    "2. label_seg (int): 12 segments based on age and income\n",
    "    - values: 1 ... 12  <br>  \n",
    "  \n",
    "(More details in <u>2_heuristic_exploration.ipynb</u>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <u>10 Kinds</u> of offer_id\n",
    "| offer_id #| type | duration | requirement | reward |\n",
    "|:-| :-| :-:|:-:|:-:|\n",
    "| 0 | bogo | 7 | 10 | 10 |\n",
    "| 1 | bogo | 5 | 10 | 10 |\n",
    "| 2 | infomational | 4 | - | - |\n",
    "| 3 | bogo | 7 | 5 | 5 |\n",
    "| 4 | discount | 10 | 20 | 5 |\n",
    "| 5 | discount | 7 | 7 | 3 |\n",
    "| 6 | discount | 10 | 10 | 2 |\n",
    "| 7 | informational | 3 | - | - |\n",
    "| 8 | bogo | 5 | 5 | 5 |\n",
    "| 9 | discount | 7 | 10 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>12 Segements</u> based on 'age' and 'income'\n",
    "<br>\n",
    "    \n",
    "|Segment #| Age Group (edge included)<br> (Experiment in 2018) | Income | \n",
    "|---| --- | --- | \n",
    "|1| Millenials(-21 & 22-37) | low  | \n",
    "|2| Millenials(-21 & 22-37) | medium  | \n",
    "|3| Millenials(-21 & 22-37) | high  | \n",
    "|4| Gen X(38-53) | low  |\n",
    "|5| Gen X(38-53) | medium |\n",
    "|6| Gen X(38-53) | high |\n",
    "|7| Baby Boomer(54-72) | low  |\n",
    "|8| Baby Boomer(54-72) | medium |\n",
    "|9| Baby Boomer(54-72) | high |\n",
    "|10| Silent(73-90 & 91+) |low |\n",
    "|11| Silent(73-90 & 91+) | medium |\n",
    "|12| Silent(73-90 & 91+) | high |\n",
    "\n",
    "**Notice:**  \n",
    "- low: 30,000-50,000\n",
    "- medium: 50,001-82,500\n",
    "- high: 82,501-120,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>4 Groups</u> of possible responsiveness to offer\n",
    "<br>\n",
    "\n",
    "|Group| received | viewed |valid completed | transaction amount |Scenario |\n",
    "| :-| :-: | :-:| :-: | :-: | :- |\n",
    "|1.none_offer| 0 | 0 | 0 | |haven't received the offer |\n",
    "|2.no_care | 1 | 0 | - | |received but not viewed.<br> regarded as no_care|\n",
    "|| 1 | 1 | 0 | =0.0 | received, viewed but no transaction |\n",
    "|| 1 | 1 | 1<br>viewed after completed |  | received, but completed unintentionally |\n",
    "|3.tried| 1 | 1 | 0 | >0.0|received, viewed, have transaction |\n",
    "|4.effctive_offer | 1 | 1 | 1<br>viewed before completed | | viewed before completed,  effctive offer|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a class=\"anchor\" id=\"Start\">Table of Contents</a>\n",
    "\n",
    "I. [Feature Engineer](#1)<br>\n",
    "II.[Build model Pipeline](#2)<br>\n",
    "III.[Explore intersting Questions](#3)  \n",
    "- Q3.1 [Offer prepared to sent to a person, will this offer effective?](#3.1)\n",
    "- Q3.2 [Offer already sent to a person, is this offer effective?](#3.2)\n",
    "- Q3.3 [Given a person, recommend an offer with the most effctivity?](#3.3)\n",
    "\n",
    "IV.[Build Neural Network for Regeression](#4)<br>\n",
    "[References](#References)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "from time import time\n",
    "from datetime import date\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model_dataset_raw = pd.read_csv('./data_generated/model_dataset_raw.csv', dtype={'offer_id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"1\">[I. Feature Engineer](#Start)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Add features\n",
    "- Total transactions amount of individuals `'amount_total'`\n",
    "- Count of offers received of individuals  `'offer_received_cnt'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in transactions dataset\n",
    "\n",
    "# wrangled transcript with updated information of 'offer_id'\n",
    "transcript_offer = pd.read_csv('./data_generated/transcript_offer_wrangled.csv', dtype={'person': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total transactions amount of individuals \n",
    "transcript_amount = transcript_offer.groupby('person').sum()['amount']\n",
    "# Count of offers received of individuals\n",
    "offer_received_cnt = model_dataset_raw.groupby(['person']).count()['offer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# person ids\n",
    "persons = transcript_amount.index.tolist()\n",
    "\n",
    "for person in persons:\n",
    "    # update the two features in model_dataset_raw\n",
    "    is_person = (model_dataset_raw.person == person)\n",
    "    model_dataset_raw.loc[is_person,'amount_total'] = transcript_amount.loc[person]\n",
    "    model_dataset_raw.loc[is_person,'offer_received_cnt'] = offer_received_cnt.loc[person]\n",
    "\n",
    "# make an copy\n",
    "model_dataset = model_dataset_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>time_received</th>\n",
       "      <th>time_viewed</th>\n",
       "      <th>time_transaction</th>\n",
       "      <th>time_completed</th>\n",
       "      <th>amount_with_offer</th>\n",
       "      <th>label_effective_offer</th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>...</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>member_days</th>\n",
       "      <th>label_seg</th>\n",
       "      <th>amount_total</th>\n",
       "      <th>offer_received_cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>effctive_offer</th>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>...</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "      <td>26826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_care</th>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>14972</td>\n",
       "      <td>22859</td>\n",
       "      <td>13581</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>...</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none_offer</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tried</th>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>0</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>...</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                person  offer_id  time_received  time_viewed  \\\n",
       "label_group                                                    \n",
       "effctive_offer   26826     26826          26826        26826   \n",
       "no_care          31613     31613          31613        14972   \n",
       "none_offer           5         5              0            0   \n",
       "tried             8062      8062           8062         8062   \n",
       "\n",
       "                time_transaction  time_completed  amount_with_offer  \\\n",
       "label_group                                                           \n",
       "effctive_offer             26826           26826              26826   \n",
       "no_care                    22859           13581              31613   \n",
       "none_offer                     5               0                  5   \n",
       "tried                       8062               0               8062   \n",
       "\n",
       "                label_effective_offer  reward  difficulty  ...  mobile  \\\n",
       "label_group                                                ...           \n",
       "effctive_offer                  26826   26826       26826  ...   26826   \n",
       "no_care                         31613   31613       31613  ...   31613   \n",
       "none_offer                          5       0           0  ...       0   \n",
       "tried                            8062    8062        8062  ...    8062   \n",
       "\n",
       "                social    web  gender    age  income  member_days  label_seg  \\\n",
       "label_group                                                                    \n",
       "effctive_offer   26826  26826   26826  26826   26826        26826      26826   \n",
       "no_care          31613  31613   31613  31613   31613        31613      31613   \n",
       "none_offer           0      0       5      5       5            5          5   \n",
       "tried             8062   8062    8062   8062    8062         8062       8062   \n",
       "\n",
       "                amount_total  offer_received_cnt  \n",
       "label_group                                       \n",
       "effctive_offer         26826               26826  \n",
       "no_care                31613               31613  \n",
       "none_offer                 5                   5  \n",
       "tried                   8062                8062  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset.groupby('label_group').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOUND:**\n",
    "1. The 5 person in group `none_offer` will be droped, so that there is no more NaNs in the target columns in `model_dataset` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_dataset_kepp = (model_dataset.label_group != 'none_offer')\n",
    "model_dataset = model_dataset[is_dataset_kepp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. One-hot code for target obejects\n",
    "- gender\n",
    "- label_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_onehot = pd.get_dummies(model_dataset['gender'], prefix='gender')\n",
    "label_group_onehot = pd.get_dummies(model_dataset['label_group'], prefix='group')\n",
    "offer_id_onehot =  pd.get_dummies(model_dataset['offer_id'], prefix='offer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = pd.concat([model_dataset, gender_onehot, label_group_onehot, offer_id_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Features of time\n",
    "1. Time features\n",
    "    - 'time_received'\n",
    "    - 'time_viewed'\n",
    "    - 'time_transaction'\n",
    "    - 'time_completed'\n",
    "2. Transform the time_transaction to transaction_cnt\n",
    "3. Fill the NaNs with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '7'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset[(model_dataset.time_transaction.isin(['-1']))].offer_id.unique()  \n",
    "# Result: '-1' exists only in offer_id (2, 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_transaction_cnt(dataset):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        Since more than one transactions may exist in one offer. \n",
    "        So from the value extract the count of transactions of individuals.\n",
    "        There are three diffirent situations:\n",
    "        \n",
    "        i. Offer id is 2, 7, value of time_transaction is float:\n",
    "            - When none valid transaction, is -1 ==> len(str(x).split(','))-1 result: 0\n",
    "            - When there is a valid transaction e.g. 2.0 ==> special case!!!\n",
    "        \n",
    "        ii. Offer id is not 2, 7, value of time_transaction is str:\n",
    "            - When none valid transaction, is \"\" ==> len(str(x).split(','))-1 result: 0\n",
    "            - When a valid transaction exists e.g. \",2.0\" ==> len(str(x).split(','))-1 result: 1\n",
    "            - When more than one transaction exists e.g. \",2.0,3.0\" ==> len(str(x).split(','))-1 result: 2\n",
    "    '''\n",
    "    dataset['time_transaction'] = dataset['time_transaction'].apply(lambda x: len(str(x).split(','))-1)\n",
    "    # special case: offer id is 2 or 7, and is completed(exist one valid transaction)\n",
    "    is_group_info = (dataset.offer_id.isin(['2', '7']) & (dataset.label_effective_offer==1))\n",
    "    dataset.loc[is_group_info, 'time_transaction'] = 1\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "model_dataset = transform_transaction_cnt(model_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 66501 entries, 0 to 66505\n",
      "Data columns (total 39 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   person                66501 non-null  int64  \n",
      " 1   offer_id              66501 non-null  object \n",
      " 2   time_received         66501 non-null  float64\n",
      " 3   time_viewed           66501 non-null  float64\n",
      " 4   transaction_cnt       66501 non-null  int64  \n",
      " 5   time_completed        66501 non-null  float64\n",
      " 6   amount_with_offer     66501 non-null  float64\n",
      " 7   reward                66501 non-null  float64\n",
      " 8   difficulty            66501 non-null  float64\n",
      " 9   duration              66501 non-null  float64\n",
      " 10  offer_type            66501 non-null  object \n",
      " 11  email                 66501 non-null  float64\n",
      " 12  mobile                66501 non-null  float64\n",
      " 13  social                66501 non-null  float64\n",
      " 14  web                   66501 non-null  float64\n",
      " 15  gender                66501 non-null  object \n",
      " 16  age                   66501 non-null  int64  \n",
      " 17  income                66501 non-null  float64\n",
      " 18  member_days           66501 non-null  int64  \n",
      " 19  label_group           66501 non-null  object \n",
      " 20  label_seg             66501 non-null  int64  \n",
      " 21  amount_total          66501 non-null  float64\n",
      " 22  offer_received_cnt    66501 non-null  float64\n",
      " 23  gender_F              66501 non-null  uint8  \n",
      " 24  gender_M              66501 non-null  uint8  \n",
      " 25  gender_O              66501 non-null  uint8  \n",
      " 26  group_effctive_offer  66501 non-null  uint8  \n",
      " 27  group_no_care         66501 non-null  uint8  \n",
      " 28  group_tried           66501 non-null  uint8  \n",
      " 29  offer_0               66501 non-null  uint8  \n",
      " 30  offer_1               66501 non-null  uint8  \n",
      " 31  offer_2               66501 non-null  uint8  \n",
      " 32  offer_3               66501 non-null  uint8  \n",
      " 33  offer_4               66501 non-null  uint8  \n",
      " 34  offer_5               66501 non-null  uint8  \n",
      " 35  offer_6               66501 non-null  uint8  \n",
      " 36  offer_7               66501 non-null  uint8  \n",
      " 37  offer_8               66501 non-null  uint8  \n",
      " 38  offer_9               66501 non-null  uint8  \n",
      "dtypes: float64(14), int64(5), object(4), uint8(16)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "model_dataset.rename(columns={'time_transaction': 'transaction_cnt'}, inplace=True)\n",
    "\n",
    "# drop the useless columns for modeling\n",
    "model_dataset.drop(['label_effective_offer'], axis=1, inplace=True)\n",
    "\n",
    "# fill the NaNs\n",
    "values = {'time_viewed': 0.0, 'time_completed': 0.0} #time_viewed: 49860 non-null, time_completed: 40407 non-null\n",
    "model_dataset.fillna(value=values, inplace=True)\n",
    "\n",
    "model_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"2\">[II. Build model Pipeline](#Start)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an copy\n",
    "model_dataset_test = model_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover to the model_dataset\n",
    "# model_dataset = model_dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select features and target \n",
    "[References[1]](https://github.com/syuenloh/UdacityDataScientistCapstone/blob/master/Starbucks%20Capstone%20Challenge%20-%20Using%20Starbucks%20app%20user%20data%20to%20predict%20effective%20offers.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>time_received</th>\n",
       "      <th>time_viewed</th>\n",
       "      <th>transaction_cnt</th>\n",
       "      <th>time_completed</th>\n",
       "      <th>amount_with_offer</th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>offer_0</th>\n",
       "      <th>offer_1</th>\n",
       "      <th>offer_2</th>\n",
       "      <th>offer_3</th>\n",
       "      <th>offer_4</th>\n",
       "      <th>offer_5</th>\n",
       "      <th>offer_6</th>\n",
       "      <th>offer_7</th>\n",
       "      <th>offer_8</th>\n",
       "      <th>offer_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>...</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "      <td>31613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>...</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "      <td>34888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             person  offer_id  time_received  time_viewed  transaction_cnt  \\\n",
       "label_group                                                                  \n",
       "0             31613     31613          31613        31613            31613   \n",
       "1             34888     34888          34888        34888            34888   \n",
       "\n",
       "             time_completed  amount_with_offer  reward  difficulty  duration  \\\n",
       "label_group                                                                    \n",
       "0                     31613              31613   31613       31613     31613   \n",
       "1                     34888              34888   34888       34888     34888   \n",
       "\n",
       "             ...  offer_0  offer_1  offer_2  offer_3  offer_4  offer_5  \\\n",
       "label_group  ...                                                         \n",
       "0            ...    31613    31613    31613    31613    31613    31613   \n",
       "1            ...    34888    34888    34888    34888    34888    34888   \n",
       "\n",
       "             offer_6  offer_7  offer_8  offer_9  \n",
       "label_group                                      \n",
       "0              31613    31613    31613    31613  \n",
       "1              34888    34888    34888    34888  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target: label_group\n",
    "# Change the label of group to 0-1 variables\n",
    "model_dataset['label_group'] = model_dataset['label_group'].replace(['no_care','tried', 'effctive_offer'],['0','1','1'])\n",
    "model_dataset = model_dataset.astype({'label_group': int})\n",
    "\n",
    "model_dataset.groupby('label_group').count()  \n",
    "# 31613\t VS 34888: The distribution of the targets seems balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_target(df, target_cols, keep_cols):\n",
    "    '''\n",
    "    INPUT:\n",
    "        - df(DataFrame): dataset include all possible features and target\n",
    "        - target_cols: \n",
    "            i. (str) a column name \n",
    "            ii. (list of str) more columns names\n",
    "        - keep_cols(list): list of columns names as features\n",
    "    \n",
    "    OUTPUT:\n",
    "        - features(DataFrame)\n",
    "        - target(DataFrame)\n",
    "    '''\n",
    "    # df[[]] is DataFrame\n",
    "    target = df[target_cols] #np.array()\n",
    "    # get the drop columns names\n",
    "    drop_cols = np.setdiff1d(df.columns, keep_cols)\n",
    "    features = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. prepare model pipeline\n",
    "[References[1]](https://github.com/syuenloh/UdacityDataScientistCapstone/blob/master/Starbucks%20Capstone%20Challenge%20-%20Using%20Starbucks%20app%20user%20data%20to%20predict%20effective%20offers.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_clf(pickle_path, clf_list, features, target, test_size=0.20, random_state=9):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        Train and test the models with diffirent classifiers, and evaluate the model.\n",
    "\n",
    "    INPUT:\n",
    "        - pickle_path(str): the pickle file path to save models\n",
    "        - clf_list(list): list of classifiers\n",
    "        - features(DataFrame)\n",
    "        - target(DataFrame)\n",
    "        - test_size: the ratio of test set\n",
    "        - random_state: control random seed\n",
    "\n",
    "    OUTPUT:\n",
    "        - results_df(DataFrame): with infomation of classifier, train time, train score, test time, test score\n",
    "    '''\n",
    "    # split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                        test_size=test_size,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    results = defaultdict()\n",
    "    results_df = pd.DataFrame(columns=['model', 'train_time', 'test_time',\n",
    "                                         'train_score', 'test_score'])\n",
    "\n",
    "    for classifier in clf_list:\n",
    "        pipe = Pipeline(steps=[('preprocessor', StandardScaler()),\n",
    "                               ('clf', classifier)])\n",
    "\n",
    "        train_start = time()\n",
    "        model = pipe.fit(X_train, y_train)\n",
    "        train_end = time()\n",
    "        results['train_time'] = train_end-train_start\n",
    "\n",
    "        # predict in train set\n",
    "        pred_train = model.predict(X_train)\n",
    "\n",
    "        # predict in test set and Calculate the time\n",
    "        test_start = time()\n",
    "        pred_test = model.predict(X_test)\n",
    "        test_end = time()\n",
    "        results['test_time'] = test_end-test_start\n",
    "\n",
    "        # add training accuracy to results\n",
    "        results['train_score']=model.score(X_train,y_train)\n",
    "\n",
    "        #add testing accuracy to results\n",
    "        results['test_score']=model.score(X_test,y_test)\n",
    "\n",
    "        print(\"{} trained on {} samples.\".format(classifier.__class__.__name__, len(y_train)))\n",
    "        print(\"Train time: {}s\".format(results['train_time']))\n",
    "        print(\"Test time: {}s\".format(results['test_time']))\n",
    "        print(\"MSE_train: %.4f\" % mean_squared_error(y_train,pred_train))\n",
    "        print(\"MSE_test: %.4f\" % mean_squared_error(y_test,pred_test))\n",
    "        print(\"Training accuracy: %.4f\" % results['train_score'])\n",
    "        print(\"Test accuracy: %.4f\" % results['test_score'])\n",
    "\n",
    "        # output the report\n",
    "        report = classification_report(y_test, pred_test, digits=4) #output_dict=True\n",
    "        print(report)\n",
    "        # df_report = pd.DataFrame(report).transpose()\n",
    "        # report_ls.append(df_report)\n",
    "\n",
    "        # for scaler value need an index\n",
    "        new_model = pd.Series([classifier.__class__.__name__, results['train_time'], results['test_time'], results['train_score'], results['test_score']], index=results_df.columns)\n",
    "        results_df = results_df.append(new_model, ignore_index=True)\n",
    "\n",
    "        # Save all the models with 'ab' \n",
    "        with open(pickle_path, \"ab\") as f: # len = results_df.shape[0]\n",
    "                pickle.dump(model, f)\n",
    "\n",
    "    return results_df #,report_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model_param(classifier, param_grid, features, target, test_size=0.20, random_state=9):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        After chosen a model with classifier, try to find the best set of parameters of this model.\n",
    "\n",
    "    INPUT:\n",
    "        - classifier(clf object): the chosen classifier\n",
    "        - param_grid: alternative parameters list, used to do GridSearchCV\n",
    "        - features(DataFrame)\n",
    "        - target(DataFrame)\n",
    "        - test_size: the ratio of test set\n",
    "        - random_state: control random seed\n",
    "\n",
    "    OUTPUT:\n",
    "        - model(GridSearchCV object)\n",
    "        - results(dict): with infomation of train time, train score, test time, test score\n",
    "    '''\n",
    "\n",
    "    # split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                        test_size=test_size,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    pipe = Pipeline(steps=[('preprocessor', StandardScaler()),\n",
    "                        ('clf', classifier)])\n",
    "    model = GridSearchCV(pipe, param_grid, n_jobs= 1)\n",
    "\n",
    "    results = defaultdict()\n",
    "\n",
    "    train_start = time()\n",
    "    model.fit(X_train, y_train)  # Attribute: best_estimator_  best_params_  best_score_\n",
    "    train_end = time()\n",
    "    results['train_time'] = train_end - train_start\n",
    "\n",
    "    # predict in train set\n",
    "    pred_train = model.predict(X_train)\n",
    "\n",
    "    # predict in test set and Calculate the time\n",
    "    test_start = time()\n",
    "    pred_test = model.predict(X_test)\n",
    "    test_end = time()\n",
    "    results['test_time'] = test_end-test_start\n",
    "\n",
    "    # add training accuracy to results\n",
    "    results['train_score'] = model.score(X_train,y_train)\n",
    "\n",
    "    # add testing accuracy to results\n",
    "    results['test_score'] = model.score(X_test,y_test)\n",
    "\n",
    "    print(\"{} trained on {} samples.\".format(model.best_estimator_, len(y_train)))\n",
    "    print(\"MSE_train: %.4f\" % mean_squared_error(y_train, pred_train))\n",
    "    print(\"MSE_test: %.4f\" % mean_squared_error(y_test, pred_test))\n",
    "    print(\"Training accuracy: %.4f\" % results['train_score'])\n",
    "    print(\"Test accuracy: %.4f\" % results['test_score'])\n",
    "    print(classification_report(y_test, pred_test,digits=4))\n",
    "\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"3\">[III. Explore intersting Questions](#Start)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"3.1\">[Q3.1 Offer prepared to sent to a person, will this offer effective?](#Start)</a>\n",
    "\n",
    "1. Dataset: The data as follows (in label_group)\n",
    "    - no_care\n",
    "    - tried\n",
    "    - effective_offer\n",
    "<br>\n",
    "2. Target   \n",
    "\n",
    "| Target | Value | Meaning |\n",
    "| :- | :-: | :- |\n",
    "| label_group | 0 | person doesn't care the offer |\n",
    "|       | 1 | Within the duration of offer, person tried or completed the transactions|\n",
    "\n",
    "3. Features\n",
    "\n",
    "| (Number: default 1)Features | Select reason |\n",
    "| :- | :- |\n",
    "| age | basic info about person |\n",
    "| income | basic info about person |\n",
    "| member_days | basic info about person |\n",
    "| (3)gender_ | basic info about person<br>(3 kinds of 0-1 variables) |\n",
    "| (10)offer_ | info about offer<br>(10 kinds of 0-1 variables) |\n",
    "| amount_total | amount paid of all transactions |\n",
    "| offer_received_cnt | number of all received offers |\n",
    "| time_received | receive time for this offer |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier trained on 53200 samples.\n",
      "Train time: 2.9423346519470215s\n",
      "Test time: 13.412032127380371s\n",
      "MSE_train: 0.1824\n",
      "MSE_test: 0.3376\n",
      "Training accuracy: 0.8176\n",
      "Test accuracy: 0.6624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6421    0.6311    0.6366      6230\n",
      "           1     0.6798    0.6900    0.6849      7071\n",
      "\n",
      "    accuracy                         0.6624     13301\n",
      "   macro avg     0.6609    0.6606    0.6607     13301\n",
      "weighted avg     0.6621    0.6624    0.6622     13301\n",
      "\n",
      "SVC trained on 53200 samples.\n",
      "Train time: 1685.7050383090973s\n",
      "Test time: 22.67504072189331s\n",
      "MSE_train: 0.3005\n",
      "MSE_test: 0.3036\n",
      "Training accuracy: 0.6995\n",
      "Test accuracy: 0.6964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6717    0.6881    0.6798      6230\n",
      "           1     0.7192    0.7037    0.7114      7071\n",
      "\n",
      "    accuracy                         0.6964     13301\n",
      "   macro avg     0.6955    0.6959    0.6956     13301\n",
      "weighted avg     0.6970    0.6964    0.6966     13301\n",
      "\n",
      "NuSVC trained on 53200 samples.\n",
      "Train time: 22959.3583650589s\n",
      "Test time: 43.54108142852783s\n",
      "MSE_train: 0.2194\n",
      "MSE_test: 0.2966\n",
      "Training accuracy: 0.7806\n",
      "Test accuracy: 0.7034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6831    0.6841    0.6836      6230\n",
      "           1     0.7213    0.7204    0.7209      7071\n",
      "\n",
      "    accuracy                         0.7034     13301\n",
      "   macro avg     0.7022    0.7023    0.7022     13301\n",
      "weighted avg     0.7034    0.7034    0.7034     13301\n",
      "\n",
      "DecisionTreeClassifier trained on 53200 samples.\n",
      "Train time: 2.1007981300354004s\n",
      "Test time: 0.06896233558654785s\n",
      "MSE_train: 0.0000\n",
      "MSE_test: 0.3509\n",
      "Training accuracy: 1.0000\n",
      "Test accuracy: 0.6491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6245    0.6291    0.6268      6230\n",
      "           1     0.6711    0.6668    0.6689      7071\n",
      "\n",
      "    accuracy                         0.6491     13301\n",
      "   macro avg     0.6478    0.6479    0.6479     13301\n",
      "weighted avg     0.6493    0.6491    0.6492     13301\n",
      "\n",
      "RandomForestClassifier trained on 53200 samples.\n",
      "Train time: 27.510256052017212s\n",
      "Test time: 0.92746901512146s\n",
      "MSE_train: 0.0000\n",
      "MSE_test: 0.2782\n",
      "Training accuracy: 1.0000\n",
      "Test accuracy: 0.7218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7090    0.6886    0.6986      6230\n",
      "           1     0.7324    0.7510    0.7416      7071\n",
      "\n",
      "    accuracy                         0.7218     13301\n",
      "   macro avg     0.7207    0.7198    0.7201     13301\n",
      "weighted avg     0.7214    0.7218    0.7215     13301\n",
      "\n",
      "AdaBoostClassifier trained on 53200 samples.\n",
      "Train time: 6.932032108306885s\n",
      "Test time: 0.2628481388092041s\n",
      "MSE_train: 0.2848\n",
      "MSE_test: 0.2832\n",
      "Training accuracy: 0.7152\n",
      "Test accuracy: 0.7168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6979    0.6971    0.6975      6230\n",
      "           1     0.7334    0.7341    0.7338      7071\n",
      "\n",
      "    accuracy                         0.7168     13301\n",
      "   macro avg     0.7156    0.7156    0.7156     13301\n",
      "weighted avg     0.7168    0.7168    0.7168     13301\n",
      "\n",
      "GradientBoostingClassifier trained on 53200 samples.\n",
      "Train time: 25.96913766860962s\n",
      "Test time: 0.05796694755554199s\n",
      "MSE_train: 0.2692\n",
      "MSE_test: 0.2728\n",
      "Training accuracy: 0.7308\n",
      "Test accuracy: 0.7272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7070    0.7130    0.7100      6230\n",
      "           1     0.7452    0.7396    0.7424      7071\n",
      "\n",
      "    accuracy                         0.7272     13301\n",
      "   macro avg     0.7261    0.7263    0.7262     13301\n",
      "weighted avg     0.7273    0.7272    0.7272     13301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_cols = 'label_group'\n",
    "\n",
    "keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "            'offer_0', 'offer_1', 'offer_2', 'offer_3', 'offer_4', 'offer_5',\n",
    "              'offer_6', 'offer_7', 'offer_8', 'offer_9',\n",
    "             'amount_total', 'offer_received_cnt','time_received']\n",
    "           \n",
    "features, target = select_features_target(model_dataset, target_cols, keep_cols)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "\n",
    "# save the models and get results\n",
    "pickle_path = './models_prepare.pckl'\n",
    "results_prepare = select_clf(pickle_path, classifiers, features, target, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_time</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>2.942335</td>\n",
       "      <td>13.412032</td>\n",
       "      <td>0.817613</td>\n",
       "      <td>0.662431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1685.705038</td>\n",
       "      <td>22.675041</td>\n",
       "      <td>0.699474</td>\n",
       "      <td>0.696414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>22959.358365</td>\n",
       "      <td>43.541081</td>\n",
       "      <td>0.780620</td>\n",
       "      <td>0.703406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2.100798</td>\n",
       "      <td>0.068962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>27.510256</td>\n",
       "      <td>0.927469</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.721750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>6.932032</td>\n",
       "      <td>0.262848</td>\n",
       "      <td>0.715226</td>\n",
       "      <td>0.716788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>25.969138</td>\n",
       "      <td>0.057967</td>\n",
       "      <td>0.730808</td>\n",
       "      <td>0.727163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model    train_time  test_time  train_score  \\\n",
       "0        KNeighborsClassifier      2.942335  13.412032     0.817613   \n",
       "1                         SVC   1685.705038  22.675041     0.699474   \n",
       "2                       NuSVC  22959.358365  43.541081     0.780620   \n",
       "3      DecisionTreeClassifier      2.100798   0.068962     1.000000   \n",
       "4      RandomForestClassifier     27.510256   0.927469     0.999981   \n",
       "5          AdaBoostClassifier      6.932032   0.262848     0.715226   \n",
       "6  GradientBoostingClassifier     25.969138   0.057967     0.730808   \n",
       "\n",
       "   test_score  \n",
       "0    0.662431  \n",
       "1    0.696414  \n",
       "2    0.703406  \n",
       "3    0.649124  \n",
       "4    0.721750  \n",
       "5    0.716788  \n",
       "6    0.727163  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_prepare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"3.2\">[Q3.2 Offer already sent to a person, is this offer effective?](#Start)</a>\n",
    "1. Dataset: The data as follows (in label_group)\n",
    "    - no_care\n",
    "    - tried\n",
    "    - effective_offer\n",
    "    <br>\n",
    "2. Target   \n",
    "\n",
    "| Target | Value | Meaning |\n",
    "| :- | :-: | :- |\n",
    "| label_group | 0 | person doesn't care the offer |\n",
    "|       | 1 | Within the duration of offer, person tried or completed the transactions|\n",
    "\n",
    "3. Features\n",
    "\n",
    "| (Number: default 1)Features | Select reason |\n",
    "| :- | :- |\n",
    "| age | basic info about person |\n",
    "| income | basic info about person |\n",
    "| member_days | basic info about person |\n",
    "| (3)gender_ | basic info about person<br>(3 kinds of 0-1 variables) |\n",
    "| (10)offer_ | info about offer<br>(10 kinds of 0-1 variables) |\n",
    "| amount_total | amount paid of all transactions |\n",
    "| offer_received_cnt | number of all received offers |\n",
    "| time_received | receive time for this offer |\n",
    "| amount_with_offer | amount paid of transactions for this offer |\n",
    "| time_viewed | view time for this offer. <br>If not, values 0.0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier trained on 53200 samples.\n",
      "Train time: 1.301255226135254s\n",
      "Test time: 32.317505836486816s\n",
      "MSE_train: 0.1156\n",
      "MSE_test: 0.2151\n",
      "Training accuracy: 0.8844\n",
      "Test accuracy: 0.7849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8040    0.7151    0.7569      6230\n",
      "           1     0.7713    0.8464    0.8071      7071\n",
      "\n",
      "    accuracy                         0.7849     13301\n",
      "   macro avg     0.7876    0.7808    0.7820     13301\n",
      "weighted avg     0.7866    0.7849    0.7836     13301\n",
      "\n",
      "DecisionTreeClassifier trained on 53200 samples.\n",
      "Train time: 0.6096532344818115s\n",
      "Test time: 0.01599907875061035s\n",
      "MSE_train: 0.0000\n",
      "MSE_test: 0.1217\n",
      "Training accuracy: 1.0000\n",
      "Test accuracy: 0.8783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8628    0.8801    0.8714      6230\n",
      "           1     0.8925    0.8767    0.8845      7071\n",
      "\n",
      "    accuracy                         0.8783     13301\n",
      "   macro avg     0.8776    0.8784    0.8779     13301\n",
      "weighted avg     0.8786    0.8783    0.8783     13301\n",
      "\n",
      "RandomForestClassifier trained on 53200 samples.\n",
      "Train time: 10.02626085281372s\n",
      "Test time: 0.3507988452911377s\n",
      "MSE_train: 0.0000\n",
      "MSE_test: 0.0876\n",
      "Training accuracy: 1.0000\n",
      "Test accuracy: 0.9124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9745    0.8348    0.8993      6230\n",
      "           1     0.8708    0.9808    0.9225      7071\n",
      "\n",
      "    accuracy                         0.9124     13301\n",
      "   macro avg     0.9227    0.9078    0.9109     13301\n",
      "weighted avg     0.9194    0.9124    0.9116     13301\n",
      "\n",
      "AdaBoostClassifier trained on 53200 samples.\n",
      "Train time: 3.3161022663116455s\n",
      "Test time: 0.18491268157958984s\n",
      "MSE_train: 0.1030\n",
      "MSE_test: 0.1038\n",
      "Training accuracy: 0.8970\n",
      "Test accuracy: 0.8962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9435    0.8279    0.8819      6230\n",
      "           1     0.8632    0.9563    0.9073      7071\n",
      "\n",
      "    accuracy                         0.8962     13301\n",
      "   macro avg     0.9033    0.8921    0.8946     13301\n",
      "weighted avg     0.9008    0.8962    0.8954     13301\n",
      "\n",
      "GradientBoostingClassifier trained on 53200 samples.\n",
      "Train time: 11.604355335235596s\n",
      "Test time: 0.033998727798461914s\n",
      "MSE_train: 0.0883\n",
      "MSE_test: 0.0912\n",
      "Training accuracy: 0.9117\n",
      "Test accuracy: 0.9088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9754    0.8262    0.8946      6230\n",
      "           1     0.8650    0.9816    0.9196      7071\n",
      "\n",
      "    accuracy                         0.9088     13301\n",
      "   macro avg     0.9202    0.9039    0.9071     13301\n",
      "weighted avg     0.9167    0.9088    0.9079     13301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_cols = 'label_group'\n",
    "\n",
    "# 'group_effctive_offer', 'group_no_care', 'group_tried','transaction_cnt', 'time_completed' \n",
    "# have direct information to target classes\n",
    "keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "            'offer_0', 'offer_1', 'offer_2', 'offer_3', 'offer_4', 'offer_5',\n",
    "              'offer_6', 'offer_7', 'offer_8', 'offer_9',\n",
    "             'amount_with_offer', 'amount_total', 'offer_received_cnt',\n",
    "            'time_received', 'time_viewed']\n",
    "           \n",
    "features, target = select_features_target(model_dataset, target_cols, keep_cols)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    #SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    #NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "\n",
    "# save the models and get results\n",
    "pickle_path = './models_sent.pckl'\n",
    "results_sent = select_clf(pickle_path, classifiers, features, target, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_time</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>1.301255</td>\n",
       "      <td>32.317506</td>\n",
       "      <td>0.884398</td>\n",
       "      <td>0.784903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.609653</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>10.026261</td>\n",
       "      <td>0.350799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>3.316102</td>\n",
       "      <td>0.184913</td>\n",
       "      <td>0.897030</td>\n",
       "      <td>0.896173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>11.604355</td>\n",
       "      <td>0.033999</td>\n",
       "      <td>0.911692</td>\n",
       "      <td>0.908804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  train_time  test_time  train_score  test_score\n",
       "0        KNeighborsClassifier    1.301255  32.317506     0.884398    0.784903\n",
       "1      DecisionTreeClassifier    0.609653   0.015999     1.000000    0.878280\n",
       "2      RandomForestClassifier   10.026261   0.350799     1.000000    0.912413\n",
       "3          AdaBoostClassifier    3.316102   0.184913     0.897030    0.896173\n",
       "4  GradientBoostingClassifier   11.604355   0.033999     0.911692    0.908804"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a claa=\"anchor\" id=\"3.3\">[Q3.3 Given a person, recommend an offer with the most effctivity.](#Start)</a>\n",
    "\n",
    "1. Dataset: The data as follows (in label_group)\n",
    "    - tried: in this group exists transaction(s)\n",
    "    - effective_offer\n",
    "<br>\n",
    "2. Target\n",
    "\n",
    "| Target | Value | Meaning |\n",
    "| :- | :-: | :- |\n",
    "| offer_(10 classes) | 0 | uneffective in this offer_id |\n",
    "|              | 1 | effective in this offer_id |\n",
    "\n",
    "3. Features\n",
    "\n",
    "| (Number: default 1)Features | Select reason |\n",
    "| :- | :- |\n",
    "| age | basic info about person |\n",
    "| income | basic info about person |\n",
    "| member_days | basic info about person |\n",
    "| (3)gender_ | basic info about person<br>(3 kinds of 0-1 variables) |\n",
    "| amount_total | amount paid of all transactions |\n",
    "| offer_received_cnt | number of all received offers |\n",
    "| time_received | receive time for this offer |\n",
    "| amount_with_offer | amount paid of transactions for this offer |\n",
    "| time_viewed | view time for this offer. <br>If not, values 0.0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_group_effective = (model_dataset.label_group==1)  # tried & effctive_offer\n",
    "model_dataset_effective = model_dataset[is_group_effective]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>time_received</th>\n",
       "      <th>time_viewed</th>\n",
       "      <th>transaction_cnt</th>\n",
       "      <th>time_completed</th>\n",
       "      <th>amount_with_offer</th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>...</th>\n",
       "      <th>offer_0</th>\n",
       "      <th>offer_1</th>\n",
       "      <th>offer_2</th>\n",
       "      <th>offer_3</th>\n",
       "      <th>offer_4</th>\n",
       "      <th>offer_5</th>\n",
       "      <th>offer_6</th>\n",
       "      <th>offer_7</th>\n",
       "      <th>offer_8</th>\n",
       "      <th>offer_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>...</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>...</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>...</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>...</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "      <td>2340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>...</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "      <td>1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>...</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "      <td>4964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>...</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "      <td>5351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>...</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "      <td>2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>...</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>...</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          person  time_received  time_viewed  transaction_cnt  time_completed  \\\n",
       "offer_id                                                                        \n",
       "0           4574           4574         4574             4574            4574   \n",
       "1           4645           4645         4645             4645            4645   \n",
       "2           1623           1623         1623             1623            1623   \n",
       "3           2340           2340         2340             2340            2340   \n",
       "4           1686           1686         1686             1686            1686   \n",
       "5           4964           4964         4964             4964            4964   \n",
       "6           5351           5351         5351             5351            5351   \n",
       "7           2869           2869         2869             2869            2869   \n",
       "8           4473           4473         4473             4473            4473   \n",
       "9           2363           2363         2363             2363            2363   \n",
       "\n",
       "          amount_with_offer  reward  difficulty  duration  offer_type  ...  \\\n",
       "offer_id                                                               ...   \n",
       "0                      4574    4574        4574      4574        4574  ...   \n",
       "1                      4645    4645        4645      4645        4645  ...   \n",
       "2                      1623    1623        1623      1623        1623  ...   \n",
       "3                      2340    2340        2340      2340        2340  ...   \n",
       "4                      1686    1686        1686      1686        1686  ...   \n",
       "5                      4964    4964        4964      4964        4964  ...   \n",
       "6                      5351    5351        5351      5351        5351  ...   \n",
       "7                      2869    2869        2869      2869        2869  ...   \n",
       "8                      4473    4473        4473      4473        4473  ...   \n",
       "9                      2363    2363        2363      2363        2363  ...   \n",
       "\n",
       "          offer_0  offer_1  offer_2  offer_3  offer_4  offer_5  offer_6  \\\n",
       "offer_id                                                                  \n",
       "0            4574     4574     4574     4574     4574     4574     4574   \n",
       "1            4645     4645     4645     4645     4645     4645     4645   \n",
       "2            1623     1623     1623     1623     1623     1623     1623   \n",
       "3            2340     2340     2340     2340     2340     2340     2340   \n",
       "4            1686     1686     1686     1686     1686     1686     1686   \n",
       "5            4964     4964     4964     4964     4964     4964     4964   \n",
       "6            5351     5351     5351     5351     5351     5351     5351   \n",
       "7            2869     2869     2869     2869     2869     2869     2869   \n",
       "8            4473     4473     4473     4473     4473     4473     4473   \n",
       "9            2363     2363     2363     2363     2363     2363     2363   \n",
       "\n",
       "          offer_7  offer_8  offer_9  \n",
       "offer_id                             \n",
       "0            4574     4574     4574  \n",
       "1            4645     4645     4645  \n",
       "2            1623     1623     1623  \n",
       "3            2340     2340     2340  \n",
       "4            1686     1686     1686  \n",
       "5            4964     4964     4964  \n",
       "6            5351     5351     5351  \n",
       "7            2869     2869     2869  \n",
       "8            4473     4473     4473  \n",
       "9            2363     2363     2363  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset_effective.groupby('offer_id').count()  #seems that the samples is far from enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier trained on 27910 samples.\n",
      "Train time: 0.535691499710083s\n",
      "Test time: 5.152048826217651s\n",
      "MSE_train: 0.0870\n",
      "MSE_test: 0.1235\n",
      "Training accuracy: 0.2369\n",
      "Test accuracy: 0.0489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1377    0.0499    0.0732       922\n",
      "           1     0.1559    0.0571    0.0836       928\n",
      "           2     0.0370    0.0060    0.0104       331\n",
      "           3     0.1058    0.0234    0.0383       471\n",
      "           4     0.1622    0.0178    0.0320       338\n",
      "           5     0.1521    0.0649    0.0910      1017\n",
      "           6     0.1670    0.0768    0.1052      1016\n",
      "           7     0.1481    0.0367    0.0588       545\n",
      "           8     0.1682    0.0576    0.0858       938\n",
      "           9     0.0538    0.0106    0.0177       472\n",
      "\n",
      "   micro avg     0.1470    0.0489    0.0734      6978\n",
      "   macro avg     0.1288    0.0401    0.0596      6978\n",
      "weighted avg     0.1400    0.0489    0.0713      6978\n",
      " samples avg     0.0489    0.0489    0.0489      6978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\JustPractice\\1_MS_Geek_salute\\PythonAnaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier trained on 27910 samples.\n",
      "Train time: 2.1677582263946533s\n",
      "Test time: 0.016993045806884766s\n",
      "MSE_train: 0.0000\n",
      "MSE_test: 0.1702\n",
      "Training accuracy: 1.0000\n",
      "Test accuracy: 0.1489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1765    0.1757    0.1761       922\n",
      "           1     0.1470    0.1476    0.1473       928\n",
      "           2     0.0799    0.0755    0.0776       331\n",
      "           3     0.0640    0.0658    0.0649       471\n",
      "           4     0.2123    0.2041    0.2081       338\n",
      "           5     0.1762    0.1701    0.1731      1017\n",
      "           6     0.1810    0.1890    0.1849      1016\n",
      "           7     0.1439    0.1486    0.1462       545\n",
      "           8     0.1302    0.1269    0.1285       938\n",
      "           9     0.1029    0.1059    0.1044       472\n",
      "\n",
      "   micro avg     0.1489    0.1489    0.1489      6978\n",
      "   macro avg     0.1414    0.1409    0.1411      6978\n",
      "weighted avg     0.1490    0.1489    0.1489      6978\n",
      " samples avg     0.1489    0.1489    0.1489      6978\n",
      "\n",
      "RandomForestClassifier trained on 27910 samples.\n",
      "Train time: 31.097193479537964s\n",
      "Test time: 1.2302966117858887s\n",
      "MSE_train: 0.0000\n",
      "MSE_test: 0.1009\n",
      "Training accuracy: 0.9995\n",
      "Test accuracy: 0.0082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3235    0.0119    0.0230       922\n",
      "           1     0.0000    0.0000    0.0000       928\n",
      "           2     0.0000    0.0000    0.0000       331\n",
      "           3     0.0000    0.0000    0.0000       471\n",
      "           4     0.4118    0.0207    0.0394       338\n",
      "           5     0.2778    0.0049    0.0097      1017\n",
      "           6     0.1471    0.0049    0.0095      1016\n",
      "           7     0.5294    0.0495    0.0906       545\n",
      "           8     0.0833    0.0011    0.0021       938\n",
      "           9     0.5000    0.0021    0.0042       472\n",
      "\n",
      "   micro avg     0.3239    0.0082    0.0159      6978\n",
      "   macro avg     0.2273    0.0095    0.0179      6978\n",
      "weighted avg     0.2110    0.0082    0.0154      6978\n",
      " samples avg     0.0082    0.0082    0.0082      6978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\JustPractice\\1_MS_Geek_salute\\PythonAnaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier trained on 27910 samples.\n",
      "Train time: 54.60474991798401s\n",
      "Test time: 0.12692713737487793s\n",
      "MSE_train: 0.0985\n",
      "MSE_test: 0.1000\n",
      "Training accuracy: 0.0191\n",
      "Test accuracy: 0.0103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4783    0.0119    0.0233       922\n",
      "           1     0.0000    0.0000    0.0000       928\n",
      "           2     0.0000    0.0000    0.0000       331\n",
      "           3     0.0000    0.0000    0.0000       471\n",
      "           4     0.6774    0.0621    0.1138       338\n",
      "           5     0.0000    0.0000    0.0000      1017\n",
      "           6     0.4000    0.0020    0.0039      1016\n",
      "           7     0.5211    0.0679    0.1201       545\n",
      "           8     0.3333    0.0011    0.0021       938\n",
      "           9     0.0000    0.0000    0.0000       472\n",
      "\n",
      "   micro avg     0.4932    0.0103    0.0202      6978\n",
      "   macro avg     0.2410    0.0145    0.0263      6978\n",
      "weighted avg     0.2398    0.0103    0.0188      6978\n",
      " samples avg     0.0103    0.0103    0.0103      6978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\JustPractice\\1_MS_Geek_salute\\PythonAnaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_cols = ['offer_0', 'offer_1', 'offer_2', 'offer_3', 'offer_4', 'offer_5',\n",
    "              'offer_6', 'offer_7', 'offer_8', 'offer_9']\n",
    "\n",
    "# 'group_effctive_offer', 'group_no_care', 'group_tried','transaction_cnt', 'time_completed' \n",
    "# have direct information to target classes\n",
    "keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "             'amount_with_offer', 'amount_total', 'offer_received_cnt',\n",
    "            'time_received', 'time_viewed']\n",
    "\n",
    "features, target = select_features_target(model_dataset_effective,target_cols, keep_cols)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    #SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    #NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    #AdaBoostClassifier(),  \n",
    "    MultiOutputClassifier(GradientBoostingClassifier())  #one-vs-the rest\n",
    "    ]\n",
    "\n",
    "# test for ideal with group infos\n",
    "pickle_path = './models_rec.pckl'\n",
    "results_rec = select_clf(pickle_path, classifiers, features, target, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"4\">[IV. Build neural network for regeression](#Start)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24fb13559b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    '''Initial the neural network'''\n",
    "    def __init__(self, inputs=18, hidden=7, outputs=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(inputs, hidden)  # 18 features as input\n",
    "        self.fc2 = nn.Linear(hidden, outputs)\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)  #回归直接输出，单分类sigmoid, 多分类soft_max... \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = 'amount_total'\n",
    "\n",
    "keep_cols = ['age', 'income', 'member_days', 'gender_F', 'gender_M', 'gender_O',\n",
    "             'reward', 'difficulty','duration', 'email', 'mobile', 'social', 'web',\n",
    "             'transaction_cnt', 'offer_received_cnt',\n",
    "             'group_effctive_offer', 'group_no_care', 'group_tried']\n",
    "            \n",
    "# shuffle the dataset\n",
    "model_dataset_input = shuffle(model_dataset)\n",
    "features, target = select_features_target(model_dataset_input, target_cols, keep_cols)\n",
    "\n",
    "# change DataFrame to tensor('float')\n",
    "features_array, target_array = np.array(features), np.array(target)\n",
    "features_tensor, target_tensor = torch.from_numpy(features_array).float(), torch.from_numpy(target_array).float()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tensor, target_tensor, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\JustPractice\\1_MS_Geek_salute\\PythonAnaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/20.. Training Loss: 20550.215.. Test Loss: 16089.338.. Time Cost: 85.232s..\n",
      "epoch:2/20.. Training Loss: 18629.431.. Test Loss: 15645.789.. Time Cost: 108.798s..\n",
      "epoch:3/20.. Training Loss: 18059.719.. Test Loss: 15397.492.. Time Cost: 88.476s..\n",
      "epoch:4/20.. Training Loss: 18591.784.. Test Loss: 17092.785.. Time Cost: 84.721s..\n",
      "epoch:5/20.. Training Loss: 17867.469.. Test Loss: 16893.158.. Time Cost: 106.455s..\n",
      "epoch:6/20.. Training Loss: 17776.402.. Test Loss: 16882.059.. Time Cost: 88.753s..\n",
      "epoch:7/20.. Training Loss: 17767.603.. Test Loss: 16883.391.. Time Cost: 87.397s..\n",
      "epoch:8/20.. Training Loss: 17766.653.. Test Loss: 16884.016.. Time Cost: 97.170s..\n",
      "epoch:9/20.. Training Loss: 17766.521.. Test Loss: 16884.375.. Time Cost: 93.455s..\n",
      "epoch:10/20.. Training Loss: 17766.495.. Test Loss: 16884.461.. Time Cost: 150.855s..\n",
      "epoch:11/20.. Training Loss: 17766.488.. Test Loss: 16884.436.. Time Cost: 90.398s..\n",
      "epoch:12/20.. Training Loss: 17766.486.. Test Loss: 16884.402.. Time Cost: 75.996s..\n",
      "epoch:13/20.. Training Loss: 17766.486.. Test Loss: 16884.424.. Time Cost: 70.614s..\n",
      "epoch:14/20.. Training Loss: 17766.486.. Test Loss: 16884.420.. Time Cost: 71.088s..\n",
      "epoch:15/20.. Training Loss: 17766.486.. Test Loss: 16884.416.. Time Cost: 70.461s..\n",
      "epoch:16/20.. Training Loss: 17766.486.. Test Loss: 16884.414.. Time Cost: 84.942s..\n",
      "epoch:17/20.. Training Loss: 17766.486.. Test Loss: 16884.414.. Time Cost: 93.021s..\n",
      "epoch:18/20.. Training Loss: 17766.486.. Test Loss: 16884.414.. Time Cost: 82.828s..\n",
      "epoch:19/20.. Training Loss: 17766.486.. Test Loss: 16884.414.. Time Cost: 100.545s..\n",
      "epoch:20/20.. Training Loss: 17766.486.. Test Loss: 16884.414.. Time Cost: 94.549s..\n"
     ]
    }
   ],
   "source": [
    "# Build a model\n",
    "model = Classifier()  #default (18, 7, 1)\n",
    "criterion = nn.MSELoss() # criterion = nn.NLLLoss() 针对对分类变量\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# train the net model\n",
    "epochs = 20\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    start = time()\n",
    "    running_loss = 0\n",
    "    for idx in range(train_size):\n",
    "        features, target = X_train[idx], y_train[idx]\n",
    "        \n",
    "        # clear the previous gradient\n",
    "        optimizer.zero_grad()\n",
    "        # forward and backward\n",
    "        output = model(features)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        # update model/weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    test_loss = 0\n",
    "    with torch.no_grad(): # in test mode without calculating of gradient\n",
    "        model.eval()  # in test mode without dropout()\n",
    "        \n",
    "        for idx in range(test_size):\n",
    "            features, target = X_test[idx], y_test[idx]\n",
    "            \n",
    "            output = model(features)  #回归分析，没有标签accuracy的计算\n",
    "            test_loss += criterion(output, target)\n",
    "            \n",
    "    train_losses.append(running_loss/train_size)\n",
    "    test_losses.append(test_loss/test_size)\n",
    "        \n",
    "    model.train() # back to train mode\n",
    "    end = time()\n",
    "    print(\"epoch:{}/{}..\" .format(e+1, epochs), \n",
    "        \"Training Loss: {:.3f}..\".format(running_loss/train_size),\n",
    "        \"Test Loss: {:.3f}..\".format(test_loss/test_size),\n",
    "        \"Time Cost: {:.3f}s..\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"References\">[References](#Start)</a>\n",
    "[[1]Starbucks Capstone Challenge: Using Starbucks app user data to predict effective offers](https://github.com/syuenloh/UdacityDataScientistCapstone/blob/master/Starbucks%20Capstone%20Challenge%20-%20Using%20Starbucks%20app%20user%20data%20to%20predict%20effective%20offers.ipynb)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips Summary(for myself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "1. Attribute:\n",
    "    - best_estimator_  \n",
    "    - best_params_  \n",
    "    - best_score_\n",
    "    - feature_importances_\n",
    "    ```python\n",
    "    feature_importances = pd.DataFrame(models['clf'].feature_importances_,\n",
    "                           index = columns, columns=['importance']).sort_values('importance',ascending=False)\n",
    "    \n",
    "    feature_importances.plot.bar()  # series 直接画图  .hist()\n",
    "    plt.xticks(rotation=80)\n",
    "                               \n",
    "                                    \n",
    "    ```\n",
    "\n",
    "2. Method:\n",
    "    - .predict_proba(X_test): 返回概率值  第一列为0， 第二列为1  10 lables * 3 recods(inputs) * 2 outputs\n",
    "\n",
    "3. Data I/O\n",
    "    ```python\n",
    "    with open(r\"./.pckl\", \"rb\") as f:\n",
    "        # 加载1个模型\n",
    "        models = pickle.load(f)  \n",
    "        \n",
    "        # 加载多个模型\n",
    "        while True:\n",
    "        try:\n",
    "            models=pickle.load(f)\n",
    "            print(models)\n",
    "        except EOFError:\n",
    "            break\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN with Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "net = NeuralNetClassifier(MyModule, max_epochs=10, lr=0.1,)\n",
    "pipe = Pipeline([('preprocessor', StandardScaler()),\n",
    "             ('clf', net)\n",
    "            ])\n",
    "pipe.fit\n",
    "\n",
    "# 但是训练过程中如何设置：dropout()还有梯度清零，反向更新？\n",
    "# model.eval()  model.train()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
