{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 星巴克毕业项目\n",
    "\n",
    "### 简介\n",
    "\n",
    "这个数据集是一些模拟 Starbucks rewards 移动 app 上用户行为的数据。每隔几天，星巴克会向 app 的用户发送一些推送。这个推送可能仅仅是一条饮品的广告或者是折扣券或 BOGO（买一送一）。一些顾客可能一连几周都收不到任何推送。 \n",
    "\n",
    "顾客收到的推送可能是不同的，这就是这个数据集的挑战所在。\n",
    "\n",
    "你的任务是将交易数据、人口统计数据和推送数据结合起来判断哪一类人群会受到某种推送的影响。这个数据集是从星巴克 app 的真实数据简化而来。因为下面的这个模拟器仅产生了一种饮品， 实际上星巴克的饮品有几十种。\n",
    "\n",
    "每种推送都有有效期。例如，买一送一（BOGO）优惠券推送的有效期可能只有 5 天。你会发现数据集中即使是一些消息型的推送都有有效期，哪怕这些推送仅仅是饮品的广告，例如，如果一条消息型推送的有效期是 7 天，你可以认为是该顾客在这 7 天都可能受到这条推送的影响。\n",
    "\n",
    "数据集中还包含 app 上支付的交易信息，交易信息包括购买时间和购买支付的金额。交易信息还包括该顾客收到的推送种类和数量以及看了该推送的时间。顾客做出了购买行为也会产生一条记录。 \n",
    "\n",
    "同样需要记住有可能顾客购买了商品，但没有收到或者没有看推送。\n",
    "\n",
    "### 示例\n",
    "\n",
    "举个例子，一个顾客在周一收到了满 10 美元减 2 美元的优惠券推送。这个推送的有效期从收到日算起一共 10 天。如果该顾客在有效日期内的消费累计达到了 10 美元，该顾客就满足了该推送的要求。\n",
    "\n",
    "然而，这个数据集里有一些地方需要注意。即，这个推送是自动生效的；也就是说，顾客收到推送后，哪怕没有看到，满足了条件，推送的优惠依然能够生效。比如，一个顾客收到了\"满10美元减2美元优惠券\"的推送，但是该用户在 10 天有效期内从来没有打开看到过它。该顾客在 10 天内累计消费了 15 美元。数据集也会记录他满足了推送的要求，然而，这个顾客并没被受到这个推送的影响，因为他并不知道它的存在。\n",
    "\n",
    "### 清洗\n",
    "\n",
    "清洗数据非常重要也非常需要技巧。\n",
    "\n",
    "你也要考虑到某类人群即使没有收到推送，也会购买的情况。从商业角度出发，如果顾客无论是否收到推送都打算花 10 美元，你并不希望给他发送满 10 美元减 2 美元的优惠券推送。所以你可能需要分析某类人群在没有任何推送的情况下会购买什么。\n",
    "\n",
    "### 最后一项建议\n",
    "\n",
    "因为这是一个毕业项目，你可以使用任何你认为合适的方法来分析数据。例如，你可以搭建一个机器学习模型来根据人口统计数据和推送的种类来预测某人会花费多少钱。或者，你也可以搭建一个模型来预测该顾客是否会对推送做出反应。或者，你也可以完全不用搭建机器学习模型。你可以开发一套启发式算法来决定你会给每个顾客发出什么样的消息（比如75% 的35 岁女性用户会对推送 A 做出反应，对推送 B 则只有 40% 会做出反应，那么应该向她们发送推送 A）。\n",
    "\n",
    "\n",
    "# 数据集\n",
    "\n",
    "一共有三个数据文件：\n",
    "\n",
    "* portfolio.json – 包括推送的 id 和每个推送的元数据（持续时间、种类等等）\n",
    "* profile.json – 每个顾客的人口统计数据\n",
    "* transcript.json – 交易、收到的推送、查看的推送和完成的推送的记录\n",
    "\n",
    "以下是文件中每个变量的类型和解释 ：\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) – 推送的id\n",
    "* offer_type (string) – 推送的种类，例如 BOGO、打折（discount）、信息（informational）\n",
    "* difficulty (int) – 满足推送的要求所需的最少花费\n",
    "* reward (int) – 满足推送的要求后给与的优惠\n",
    "* duration (int) – 推送持续的时间，单位是天\n",
    "* channels (字符串列表)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) – 顾客的年龄 \n",
    "* became_member_on (int) – 该顾客第一次注册app的时间\n",
    "* gender (str) – 顾客的性别（注意除了表示男性的 M 和表示女性的 F 之外，还有表示其他的 O）\n",
    "* id (str) – 顾客id\n",
    "* income (float) – 顾客的收入\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) – 记录的描述（比如交易记录、推送已收到、推送已阅）\n",
    "* person (str) – 顾客id\n",
    "* time (int) – 单位是小时，测试开始时计时。该数据从时间点 t=0 开始\n",
    "* value - (dict of strings) – 推送的id 或者交易的数额\n",
    "\n",
    "**注意：**如果你正在使用 Workspace，在读取文件前，你需要打开终端/命令行，运行命令 `conda update pandas` 。因为 Workspace 中的 pandas 版本不能正确读入 transcript.json 文件的内容，所以需要更新到 pandas 的最新版本。你可以单击 notebook 左上角橘黄色的 jupyter 图标来打开终端/命令行。  \n",
    "\n",
    "下面两张图展示了如何打开终端/命令行以及如何安装更新。首先打开终端/命令行：\n",
    "<img src=\"pic1.png\"/>\n",
    "\n",
    "然后运行上面的命令：\n",
    "<img src=\"pic2.png\"/>\n",
    "\n",
    "最后回到这个 notebook（还是点击橘黄色的 jupyter 图标），再次运行下面的单元格就不会报错了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "I. [Data Discovering & Visualization](#Data-Discovering)<br>\n",
    "II.[基于排名的推荐方法](#Rank)<br>\n",
    "III.[基于用户-用户的协同过滤](#User-User)<br>\n",
    "IV.[基于内容的推荐方法（选修内容）](#Content-Recs)<br>\n",
    "V. [矩阵分解](#Matrix-Fact)<br>\n",
    "VI.[其他内容和总结](#conclusions)<br>\n",
    "[References](#references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a class=\"anchor\" id=\"Data-Discovering\">I. Data Discovering & Visualization</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic informations\n",
    "- .head()\n",
    "    - Index, Columns(Features)\n",
    "- .info()\n",
    "    - NaN values, data size\n",
    "- .describe()\n",
    "    - Statistik infomation\n",
    "- .unique()\n",
    "- .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "1. profile_cleaned (14825, 5) \n",
    "    - id\n",
    "    - gender\t\n",
    "    - age\t\t\n",
    "    - became_member_on\t\n",
    "    - income\n",
    "2. portfolio_cleaned (10, 9)\n",
    "    - id\n",
    "    - email\tmobile\tsocial\tweb\n",
    "    - reward;\tdifficulty;\toffer_type\n",
    "    - duration\t\n",
    "    \t\t\n",
    "3. transcript_cleaned (306534, 6)——>(272762, 5)legal\n",
    "    - person\t\t\n",
    "    - offer_id\t\n",
    "    - reward(useless)\n",
    "    - amount\n",
    "    - event\n",
    "    - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_cleaned.to_csv('./profile_cleaned.csv')\n",
    "portfolio_cleaned.to_csv('./portfolio_cleaned.csv')\n",
    "transcript_cleaned.to_csv('./transcript_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_cleaned = pd.read_csv('./profile_cleaned.csv')\n",
    "portfolio_cleaned= pd.read_csv('./portfolio_cleaned.csv')\n",
    "transcript_cleaned= pd.read_csv('./transcript_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_cleaned.index = profile_cleaned.iloc[:, 0].values\n",
    "del profile_cleaned['Unnamed: 0']\n",
    "\n",
    "portfolio_cleaned.index = portfolio_cleaned.iloc[:, 0].values\n",
    "del portfolio_cleaned['Unnamed: 0']\n",
    "\n",
    "transcript_cleaned.index = transcript_cleaned.iloc[:, 0].values\n",
    "del transcript_cleaned['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_cleaned.rename({'id': 'offer_id'},axis=1, inplace=True)\n",
    "transcript_offer = transcript_cleaned.merge(portfolio_cleaned[['duration','offer_id','offer_type']], how='left', on='offer_id')\n",
    "transcript_offer = transcript_offer.astype({'offer_id': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '9', '8', '2', '4', '0', '6', '1', '5', '7', '-1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_offer.offer_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = pd.DataFrame(columns=['person', 'offer_id', 'time_received', 'time_viewed', 'time_transaction','time_completed','amount_with_offer','label_effective_offer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dateset_from_unique_offer_id(groupby_offer_id, offer_id_list, transactions):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    Based on unique_offer_id of unique_person update the following dataset:\n",
    "\n",
    "    Update transactions with related offer_id in the original dataset transcript_offer.\n",
    "\n",
    "    Update target_dataset - (DataFrame), the structure of target_dataset is\n",
    "        ['person', 'offer_id', 'time_received', 'time_viewed', 'time_transaction','time_completed','amount_with_offer','label_effective_offer']\n",
    "\n",
    "    INPUT:\n",
    "        groupby_offer_id - (pandas groupby object) groupby offer_id of get_dateset_from_unique_person\n",
    "        offer_id_list - (list) offer_id list with unique values of unique person\n",
    "        transactions - (DataFrame) all transactions of a unique person\n",
    "\n",
    "    OUTPUT: None\n",
    "    '''\n",
    "    start = time()\n",
    "    \n",
    "    valid_offer_id = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    for offer_id in offer_id_list:\n",
    "        # offer_id has 10 valid values, except -1 represent nan values of offer_id\n",
    "        if offer_id not in valid_offer_id:\n",
    "            continue\n",
    "        unique_offer_id = groupby_offer_id.get_group(offer_id)\n",
    "        df_units, units_count = cut_unique_offer_id_2_units(unique_offer_id)\n",
    "\n",
    "        # informational offer_type without 'offer completed'\n",
    "        if unique_offer_id.offer_type.unique()[0] == 'informational':\n",
    "            get_dateset_from_informational_offer(df_units, units_count, transactions)\n",
    "\n",
    "        else:\n",
    "        #unique_offer_id.offer_type.unique()[0] in ['bogo', 'discount']:\n",
    "            get_dateset_from_other_offer(df_units, units_count, transactions)\n",
    "        print(\"data for unique offer_id wrangled, time is {}\" .format(time()-start))\n",
    "    print(\"data for unique person wrangled, time is {}\" .format(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_offer_id_4_transaction(original_id, updated_id):\n",
    "    '''Filling the offer_id for transactions, if they are related with an offer.\n",
    "    Final result is '-1' or a list: [offer_id_1, offer_id_2,...]\n",
    "\n",
    "    INPUT:\n",
    "        original_id - ('-1' or list) original is '-1';after updated is a list (because there will be more than one transaction related with an offer)\n",
    "        updated_id - (int) represent the related offer_id\n",
    "\n",
    "    OUTPUT:\n",
    "        lst - (list) updated offer_id infomation of transactions\n",
    "    '''\n",
    "    if original_id == '-1':  #obejct(astype('str')): str '-1'\n",
    "        new_value = updated_id\n",
    "    else:\n",
    "        # there is already at least one valid transaction related with an offer\n",
    "        new_value = original_id+','+updated_id\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dateset_from_informational_offer(df_units, units_count, transactions):\n",
    "    # target_dataset and transcript_offer are global variables.\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    For the offer_id == 2 | 7 (informational_offer)\n",
    "\n",
    "    Update transactions with related offer_id in the original dataset transcript_offer.\n",
    "\n",
    "    Update target_dataset - (DataFrame), the structure of target_dataset is\n",
    "        ['person', 'offer_id', 'time_received', 'time_viewed', 'time_transaction','time_completed','amount_with_offer','label_effective_offer']\n",
    "\n",
    "    INPUT:\n",
    "        df_units - (list of DataFrame) transaction units from a unique_offer_id of unique_person\n",
    "        units_count - (int) number of transaction units in df_units\n",
    "        transactions - (DataFrame) 'event' is 'transaction' for a unique_person\n",
    "\n",
    "    OUTPUT: None\n",
    "    '''\n",
    "    #!!!REMEMBER: it's already units, with 'offer received' or not\n",
    "    #!!!REMEMBER: units_count can't be 0, since there is no nan in 'event'\n",
    "    person   = df_units[0].person.unique()[0]  #.unique() returns a numpy.array\n",
    "    offer_id = df_units[0].offer_id.unique()[0]\n",
    "    # different offer_id has a different valid duration\n",
    "    duration = df_units[0].duration.unique()[0]\n",
    "\n",
    "    for i in range(units_count):\n",
    "        df_unit = df_units[i]\n",
    "\n",
    "        time_received = df_unit[df_unit.event=='offer received'].time.min()\n",
    "        time_viewed = df_unit[df_unit.event=='offer viewed'].time.min()\n",
    "        time_completed = df_unit[df_unit.event=='offer completed'].time.min()\n",
    "\n",
    "        # init the transaction time\n",
    "        # (after a valid transaction, the offer is finished, so there will be at most one transaction time)\n",
    "        time_transaction = -1\n",
    "        # init the amount related to an offer\n",
    "        amount_with_offer = 0\n",
    "        # init the label of effective_offer\n",
    "        label_effective_offer = -1\n",
    "\n",
    "        # FLAG of 'offer received'\n",
    "        is_received = (df_unit[df_unit.event=='offer received'].shape[0]!=0)\n",
    "\n",
    "        if is_received:\n",
    "            # at least one transaction exist\n",
    "            if transactions.shape[0] != 0:\n",
    "                transaction_time = np.array(transactions.time)\n",
    "                time_begin = time_received\n",
    "                time_end = time_received + duration\n",
    "\n",
    "                is_valid_duration = (transaction_time >= time_begin) & (transaction_time <= time_end)\n",
    "                valid_transactions = transactions[is_valid_duration]\n",
    "\n",
    "                # update the 1st transaction, get the label_effective_offer\n",
    "                if valid_transactions.shape[0] != 0:\n",
    "                    # the 1st transaction is the valid transaction related with an offer\n",
    "                    valid_transactions.head(1).loc[:, 'offer_id'] = offer_id\n",
    "                    time_transaction = valid_transactions.head(1).time.min()\n",
    "\n",
    "                    # get the data in original dataset transcript_offer, to update the offer_id of transaction with the related offer_id\n",
    "                    global transcript_offer\n",
    "                    valid_transactions_2b_labeled = transcript_offer.loc[valid_transactions.index]\n",
    "\n",
    "                    # update the offer_id of transaction in transcript_offer\n",
    "                    valid_transactions_2b_labeled['offer_id'] = valid_transactions_2b_labeled['offer_id'].apply(fill_offer_id_4_transaction, args=(offer_id,))\n",
    "                    transcript_offer.update(valid_transactions_2b_labeled)\n",
    "\n",
    "                    label_effective_offer = 1\n",
    "                    amount_with_offer = valid_transactions.head(1).amount.sum()\n",
    "\n",
    "            # received but without transaction\n",
    "            else:\n",
    "                label_effective_offer = 0\n",
    "\n",
    "        # update the target_dataset\n",
    "        global target_dataset\n",
    "        target_dataset = target_dataset.append({\n",
    "                    \"person\":   person,\n",
    "                    \"offer_id\": offer_id,\n",
    "                    \"time_received\": time_received,\n",
    "                    \"time_viewed\": time_viewed,\n",
    "                    \"time_transaction\": time_transaction,\n",
    "                    \"time_completed\": time_completed,\n",
    "                    \"amount_with_offer\": amount_with_offer,\n",
    "                    \"label_effective_offer\": label_effective_offer\n",
    "                    }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dateset_from_other_offer(df_units, units_count, transactions):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "    For the offer_id != (2 & 7)\n",
    "    (REMEMBER to exclude offer_id == -1)\n",
    "\n",
    "    Update transactions with related offer_id in the original dataset transcript_offer.\n",
    "\n",
    "    Update target_dataset - (DataFrame), the structure of target_dataset is\n",
    "        ['person', 'offer_id', 'time_received', 'time_viewed', 'time_transaction','time_completed','amount_with_offer','label_effective_offer']\n",
    "\n",
    "    INPUT:\n",
    "        df_units - (list of DataFrame) transaction units from a unique_offer_id of unique_person\n",
    "        units_count - (int) number of transaction units in df_units\n",
    "        transactions - (DataFrame) 'event' is 'transaction' for a unique_person\n",
    "\n",
    "    OUTPUT: None\n",
    "    '''\n",
    "    #!!!REMEMBER: it's already units, with 'offer received' or not\n",
    "    #!!!REMEMBER: units_count can't be 0, since there is no nan in 'event'\n",
    "    person   = df_units[0].person.unique()[0]  #.unique() returns a numpy.array\n",
    "    offer_id = df_units[0].offer_id.unique()[0]\n",
    "    # different offer_id has a different valid duration\n",
    "    duration = df_units[0].duration.unique()[0]\n",
    "\n",
    "    for i in range(units_count):\n",
    "        df_unit = df_units[i]\n",
    "\n",
    "        time_received = df_unit[df_unit.event=='offer received'].time.min()\n",
    "        time_viewed = df_unit[df_unit.event=='offer viewed'].time.min()\n",
    "        time_completed = df_unit[df_unit.event=='offer completed'].time.min()\n",
    "\n",
    "        # init the transaction time with a empty list\n",
    "        # (there will be more than one valid transaction time)\n",
    "        time_transaction = \"\"\n",
    "        # init the amount related to an offer\n",
    "        amount_with_offer = 0\n",
    "        # init the label of effective_offer\n",
    "        label_effective_offer = -1\n",
    "\n",
    "        # FLAG of 'offer received'\n",
    "        is_received = (df_unit[df_unit.event=='offer received'].shape[0]!=0)\n",
    "        # FLAG of 'offer completed'\n",
    "        is_completed = (df_unit[df_unit.event=='offer completed'].shape[0]!=0)\n",
    "\n",
    "        if is_received:\n",
    "            if is_completed:\n",
    "                #REMEMBER: to be completed, there must be transaction(s)\n",
    "                transaction_time = np.array(transactions.time)\n",
    "\n",
    "                #valid transaction(s) exist between 'offer received' and 'offer completed'\n",
    "                is_valid_duration = (transaction_time >= time_received) & (transaction_time <= time_completed)\n",
    "                valid_transactions = transactions[is_valid_duration]\n",
    "\n",
    "                valid_transactions.loc[:, 'offer_id'] = offer_id\n",
    "\n",
    "                # get the index of valid transactions, to update offer_id of transactions in the original dataset transcript_offer\n",
    "                global transcript_offer\n",
    "\n",
    "                valid_transactions_2b_labeled = transcript_offer.loc[valid_transactions.index]\n",
    "                valid_transactions_2b_labeled['offer_id']=valid_transactions_2b_labeled['offer_id'].apply(fill_offer_id_4_transaction, args=(offer_id,))\n",
    "                transcript_offer.update(valid_transactions_2b_labeled)\n",
    "\n",
    "                # update the label of effective_offer\n",
    "                label_effective_offer = 1\n",
    "                amount_with_offer = valid_transactions.amount.sum()\n",
    "                # there may be more than one valid transaction\n",
    "                for time in valid_transactions.time.values.tolist():\n",
    "                    time_transaction = time_transaction+','+str(time)\n",
    "\n",
    "\n",
    "            else:\n",
    "                # without 'offer completed'\n",
    "                transaction_time = np.array(transactions.time)\n",
    "                time_begin = time_received\n",
    "                time_end = time_received + duration\n",
    "                # transaction(s) in valid duration should be regarded as 'tried transaction(s)'\n",
    "                is_valid_duration = (transaction_time >= time_begin) & (transaction_time <= time_end)\n",
    "                valid_transactions = transactions[is_valid_duration]\n",
    "\n",
    "                # transaction(s) in valid duration should be updated with the related offer_id in the dataset transcript_offer\n",
    "\n",
    "                valid_transactions.loc[:, 'offer_id'] = offer_id\n",
    "                valid_transactions_2b_labeled = transcript_offer.loc[valid_transactions.index]\n",
    "                valid_transactions_2b_labeled['offer_id']=valid_transactions_2b_labeled['offer_id'].apply(fill_offer_id_4_transaction, args=(offer_id,))\n",
    "                transcript_offer.update(valid_transactions_2b_labeled)\n",
    "\n",
    "                label_effective_offer = 0 # tried but not completed\n",
    "                amount_with_offer = valid_transactions.amount.sum()\n",
    "                for time in valid_transactions.time.values.tolist():\n",
    "                    time_transaction = time_transaction+','+str(time)\n",
    "\n",
    "        # update the target_dataset\n",
    "        global target_dataset\n",
    "        target_dataset = target_dataset.append({\n",
    "                    \"person\":   person,\n",
    "                    \"offer_id\": offer_id,\n",
    "                    \"time_received\": time_received,\n",
    "                    \"time_viewed\": time_viewed,\n",
    "                    \"time_transaction\": time_transaction,\n",
    "                    \"time_completed\": time_completed,\n",
    "                    \"amount_with_offer\": amount_with_offer,\n",
    "                    \"label_effective_offer\": label_effective_offer\n",
    "                    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_unique_offer_id_2_units(unique_offer_id):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        The raw data is transcript of unique_offer_id in one unique_person. Since there may be more than one offer for this unique_offer_id. That's why we cut the transcript to independent pieces, and call it 'units'.\n",
    "\n",
    "    INPUT:\n",
    "        unique_offer_id - (DataFrame) transcript of unique_offer_id in one unique_person\n",
    "\n",
    "    OUTPUT:\n",
    "        df_units - (list of DataFrame) transaction units from a unique_offer_id of unique_person\n",
    "        units_count - (int) number of transaction units in df_units\n",
    "    '''\n",
    "    events = unique_offer_id['event']\n",
    "    index = events.index.values\n",
    "    index_min = events.index.min()\n",
    "    index_max = events.index.max()\n",
    "    index_received = events[events=='offer received'].index\n",
    "\n",
    "    df_units = []\n",
    "    if len(index_received) == 0:\n",
    "        units_count = 1\n",
    "        df_unit = unique_offer_id\n",
    "        df_units.append(df_unit)\n",
    "\n",
    "    elif index_received[0] == index_min:\n",
    "        units_count = len(index_received)\n",
    "        #当units_count=1时？？\n",
    "        if units_count == 1:\n",
    "            df_unit = unique_offer_id\n",
    "            df_units.append(df_unit)\n",
    "\n",
    "        else:\n",
    "            for i in range(units_count - 1):\n",
    "                df_unit = unique_offer_id[(index >= index_received[i]) & (index < index_received[i+1])]\n",
    "                df_units.append(df_unit)\n",
    "            df_unit = unique_offer_id[(index >= index_received[i+1]) & (index <= index_max)]\n",
    "            df_units.append(df_unit)\n",
    "\n",
    "    else:\n",
    "        units_count = len(index_received)+1\n",
    "        df_unit = unique_offer_id[(index >= index_min) & (index < index_received[0])]\n",
    "        df_units.append(df_unit)\n",
    "        #当units_count=2时？？\n",
    "        if units_count == 2:\n",
    "            df_unit = unique_offer_id[(index >= index_received[0]) & (index <= index_max)]\n",
    "            df_units.append(df_unit)\n",
    "        for i in range(1, units_count - 1):\n",
    "            df_unit = unique_offer_id[(index >= index_received[i]) & (index < index_received[i+1])]\n",
    "            df_units.append(df_unit)\n",
    "        df_unit = unique_offer_id[(index >= index_received[i+1]) & (index <= index_max)]\n",
    "        df_units.append(df_unit)\n",
    "\n",
    "    return df_units, units_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enjoying Test......\n",
    "1. target_dataset\n",
    "2. transcript_offer\n",
    "    - offer_id (object of str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '9', '8', '2', '4', '0', '6', '1', '5', '7', '-1']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 272762 entries, 0 to 272761\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   person      272762 non-null  int64  \n",
      " 1   event       272762 non-null  object \n",
      " 2   time        272762 non-null  float64\n",
      " 3   amount      272762 non-null  float64\n",
      " 4   offer_id    272762 non-null  object \n",
      " 5   duration    148805 non-null  float64\n",
      " 6   offer_type  148805 non-null  object \n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "####test init\n",
    "target_dataset = pd.DataFrame(columns=['person', 'offer_id', 'time_received', 'time_viewed', 'time_transaction','time_completed','amount_with_offer','label_effective_offer'])\n",
    "\n",
    "transcript_offer = transcript_cleaned.merge(portfolio_cleaned[['duration','offer_id','offer_type']], how='left', on='offer_id')\n",
    "transcript_offer = transcript_offer.astype({'offer_id': 'str'})\n",
    "\n",
    "####CHECK init\n",
    "print(transcript_offer.offer_id.unique().tolist())\n",
    "transcript_offer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '6']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transcript_offer.offer_id.unique()[-1].split(',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test for CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>time_received</th>\n",
       "      <th>time_viewed</th>\n",
       "      <th>time_transaction</th>\n",
       "      <th>time_completed</th>\n",
       "      <th>amount_with_offer</th>\n",
       "      <th>label_effective_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [person, offer_id, time_received, time_viewed, time_transaction, time_completed, amount_with_offer, label_effective_offer]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '9', '8', '2', '4', '0', '6', '1', '5', '7', '-1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_offer.offer_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PreprocessingData' from 'data_preprocessing_class' (D:\\D\\test_file\\jupyter\\Git\\Udacity_project\\4_opimize_promotion_Starbucks\\Udacity_DSND_proj4_StarbucksPromotion\\data_preprocessing_class.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-7665fae3f92d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_preprocessing_class\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreprocessingData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreprocessingData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranscript_offer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PreprocessingData' from 'data_preprocessing_class' (D:\\D\\test_file\\jupyter\\Git\\Udacity_project\\4_opimize_promotion_Starbucks\\Udacity_DSND_proj4_StarbucksPromotion\\data_preprocessing_class.py)"
     ]
    }
   ],
   "source": [
    "# import class\n",
    "from data_preprocessing_class import PreprocessingData\n",
    "data_process = PreprocessingData(target_dataset, transcript_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-1a8f709203bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moffer_id_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_person\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffer_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdata_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dateset_from_unique_offer_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroupby_offer_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffer_id_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\D\\test_file\\jupyter\\Git\\Udacity_project\\4_opimize_promotion_Starbucks\\Udacity_DSND_proj4_StarbucksPromotion\\data_preprocessing_class.py\u001b[0m in \u001b[0;36mget_dateset_from_unique_offer_id\u001b[1;34m(self, groupby_offer_id, offer_id_list, transactions)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;31m# informational offer_type without 'offer completed'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0munique_offer_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffer_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'informational'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dateset_from_informational_offer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\D\\test_file\\jupyter\\Git\\Udacity_project\\4_opimize_promotion_Starbucks\\Udacity_DSND_proj4_StarbucksPromotion\\data_preprocessing_class.py\u001b[0m in \u001b[0;36mget_dateset_from_other_offer\u001b[1;34m(self, df_units, units_count, transactions)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;31m# FLAG of 'offer received'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mis_received\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_unit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_unit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'offer received'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;31m# FLAG of 'offer completed'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0mis_completed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_unit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_unit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'offer completed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "person_ids = transcript_offer.person.unique()\n",
    "for person_id in person_ids:\n",
    "    unique_person = transcript_offer[transcript_offer['person']==person_id]\n",
    "    transactions = unique_person[unique_person.event=='transaction']\n",
    "\n",
    "    groupby_offer_id = unique_person.groupby(['offer_id'])\n",
    "    offer_id_list = unique_person.offer_id.unique()\n",
    "\n",
    "    data_process.get_dateset_from_unique_offer_id(groupby_offer_id, offer_id_list, transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process.target_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test for FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_ids = transcript_offer.person.unique()\n",
    "for person_id in person_ids:\n",
    "    unique_person = transcript_offer[transcript_offer['person']==person_id]\n",
    "    transactions = unique_person[unique_person.event=='transaction']\n",
    "\n",
    "    groupby_offer_id = unique_person.groupby(['offer_id'])\n",
    "    offer_id_list = unique_person.offer_id.unique()\n",
    "\n",
    "    get_dateset_from_unique_offer_id(groupby_offer_id, offer_id_list, transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "###test for funcs\n",
    "\n",
    "# unique_person & transactions \n",
    "person_ids = transcript_offer.person.unique()\n",
    "index = 1\n",
    "person_id = person_ids[index]\n",
    "unique_person = transcript_offer[transcript_offer['person']==person_id]\n",
    "transactions = unique_person[unique_person.event=='transaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['9', '-1', '2', '3', '6'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_offer_id = unique_person.groupby(['offer_id'])\n",
    "offer_id_list = unique_person.offer_id.unique()\n",
    "\n",
    "offer_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[       person           event  time  amount offer_id  duration     offer_type\n",
       " 47385       1  offer received   7.0     0.0        7       3.0  informational\n",
       " 75802       1    offer viewed   9.0     0.0        7       3.0  informational]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique offer_id\n",
    "offer_id = '7'\n",
    "unique_offer_id = groupby_offer_id.get_group(offer_id)\n",
    "df_units, units_count = cut_unique_offer_id_2_units(unique_offer_id)\n",
    "print(units_count)\n",
    "df_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\JustPractice\\1_MS_Geek_salute\\PythonAnaconda\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# offer_id == '2' | '7'\n",
    "get_dateset_from_informational_offer(df_units, units_count, transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offer_id != '-1'\n",
    "get_dateset_from_informational_offer(df_units, units_count, transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>time_received</th>\n",
       "      <th>time_viewed</th>\n",
       "      <th>time_transaction</th>\n",
       "      <th>time_completed</th>\n",
       "      <th>amount_with_offer</th>\n",
       "      <th>label_effective_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>,5.5</td>\n",
       "      <td>5.50</td>\n",
       "      <td>19.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>,21.25</td>\n",
       "      <td>21.25</td>\n",
       "      <td>21.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.25</td>\n",
       "      <td>,21.25</td>\n",
       "      <td>21.25</td>\n",
       "      <td>21.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>,5.5</td>\n",
       "      <td>5.50</td>\n",
       "      <td>19.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>,21.25</td>\n",
       "      <td>21.25</td>\n",
       "      <td>21.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.25</td>\n",
       "      <td>,21.25</td>\n",
       "      <td>21.25</td>\n",
       "      <td>21.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person offer_id  time_received  time_viewed time_transaction  \\\n",
       "0      1        7            7.0         9.00             9.25   \n",
       "1      1        3            0.0         0.25             ,5.5   \n",
       "2      1        7            7.0         9.00             9.25   \n",
       "3      1        0           17.0        17.00           ,21.25   \n",
       "4      1        8           21.0        24.25           ,21.25   \n",
       "5      1        3            0.0         0.25             ,5.5   \n",
       "6      1        7            7.0         9.00             9.25   \n",
       "7      1        0           17.0        17.00           ,21.25   \n",
       "8      1        8           21.0        24.25           ,21.25   \n",
       "\n",
       "   time_completed  amount_with_offer label_effective_offer  \n",
       "0             NaN              19.67                     1  \n",
       "1            5.50              19.89                     1  \n",
       "2             NaN              19.67                     1  \n",
       "3           21.25              21.72                     1  \n",
       "4           21.25              21.72                     1  \n",
       "5            5.50              19.89                     1  \n",
       "6             NaN              19.67                     1  \n",
       "7           21.25              21.72                     1  \n",
       "8           21.25              21.72                     1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_dataset\n",
    "# transcript_offer\n",
    "target_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14825"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_offer.person.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data for unique offer_id wrangled, time is 0.17090296745300293\n",
      "data for unique offer_id wrangled, time is 0.19688916206359863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\JustPractice\\1_MS_Geek_salute\\PythonAnaconda\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data for unique offer_id wrangled, time is 0.38378095626831055\n",
      "data for unique offer_id wrangled, time is 0.6016559600830078\n",
      "data for unique person wrangled, time is 0.6036555767059326\n"
     ]
    }
   ],
   "source": [
    "get_dateset_from_unique_offer_id(groupby_offer_id, offer_id_list, transactions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
